---
title: Robotics Web3 DevOps Stack
date: 2024-06-12
published: true
locale: 'nl'
tags: ['DevOps', 'Web3']
cover_image: /blog/images/web3-devops-stack/web3-devops-stack-Cover.png
description: "De DevOps-beweging heeft de IT-wereld gerevolutioneerd en onze kijk op effectieve, continue systeemverbetering veranderd. Het robotica-veld begint pas deze benadering te verkennen. In dit artikel schetsen we de mogelijke toekomst van DevOps voor robotica met behulp van Web3-technologieën. We belichten ook enkele projecten die de basis kunnen leggen voor deze toekomst."
abstract: "De DevOps-beweging heeft de IT-wereld gerevolutioneerd en onze kijk op effectieve, continue systeemverbetering veranderd. Het robotica-veld begint pas deze benadering te verkennen. In dit artikel schetsen we de mogelijke toekomst van DevOps voor robotica met behulp van Web3-technologieën. We belichten ook enkele projecten die de basis kunnen leggen voor deze toekomst."
---

## Oorsprong van Ontwikkeling & Operaties

Robots, als apparaten die de externe wereld bewegen en waarnemen, zijn een specifiek geval van computers. Zoals ingenieurs vaak zeggen, is een vliegtuig een vliegende computer, waarbij het belang van het aan boord zijnde rekenapparaat wordt benadrukt voor het behoud van de levensvatbaarheid van dit cyberfysieke systeem. Daarom kunnen we kijken naar hoe de wereld van informatiesystemen zich heeft ontwikkeld in de 21e eeuw en bepaalde trends identificeren die binnenkort inherent zullen zijn aan robotica.

Software en de praktijken die worden gebruikt voor de ontwikkeling ervan hebben aanzienlijke veranderingen teweeggebracht in benaderingen van werk in zowel engineering als elke andere activiteit. Allereerst hebben de veranderingen invloed gehad op de zogenaamde watervalbenadering, waarbij elk project werd gezien als een reeks lange afwisselende fasen: Eisen - Ontwikkeling - Verificatie - Validatie - Operatie. Na verloop van tijd bleek dat de indeling in fasen handig is voor managers, maar niet helemaal overeenkomt met hoe het in het leven gebeurt en de snelle aanpassing van producten in de omstandigheden van een voortdurend veranderende externe wereld bemoeilijkt. Agile methodologieën, die synchroon werken aan het project met kleine planningsintervallen impliceren, kwamen in de plaats van het watervalmodel van activiteit (en management). In plaats van grote fasen met mijlpalen waren er kleine sprints met incrementen - kleine maar frequente veranderingen in de ontwikkelde systemen met een snelle release. Zo'n werktempo is onhaalbaar als de release gepaard gaat met complexe administratieve procedures met handmatige controles. Zo ontstond de Ontwikkeling & Operaties-beweging om praktijken te implementeren voor het overbrengen van waarde van ontwikkelaars naar consumenten zonder verliezen en een nieuw beroep van een DevOps engineer, automatiseert het proces om het systeem snel operationeel te maken.

![devops origins](/blog/images/web3-devops-stack/devops-evolution.png)

Deze praktijken omvatten geautomatiseerd testen, continue integratie, levering, implementatie en softwaremonitoring. Geautomatiseerd testen controleert op bugs, terwijl continue integratie code wijzigingen regelmatig integreert om problemen vroegtijdig te detecteren. Levering en implementatie omvatten het beschikbaar stellen van de software aan gebruikers en installatie in hun omgeving.

In eerste instantie kregen deze praktijken momentum in het gebied van grote webservices, die miljoenen gebruikers over de hele wereld bedienen. In zo'n context zijn deze praktijken cruciaal voor het handhaven van de hoge prestaties en betrouwbaarheid die van dergelijke services worden verwacht. Na verloop van tijd en met de toenemende toegankelijkheid van automatiseringstools (mede dankzij bijdragen aan open source), is DevOps echter begonnen te worden gebruikt in meer traditionele soorten engineeringactiviteiten. Daarom hebben deze praktijken hun oorspronkelijke domein overstegen en worden ze nu toegepast in verschillende sectoren om de efficiëntie, betrouwbaarheid en kwaliteit van softwareproducten te verbeteren.

## Belangrijkste kenmerken van robots in de context van DevOps

Robots, in tegenstelling tot stationaire servers en datacenters, bewegen zich in de ruimte en nemen de externe omgeving waar. Steeds meer van dergelijke apparaten komen op de markt. We zien hun rekenkracht in de loop van de tijd toenemen - veel technische oplossingen zouden eenvoudigweg onmogelijk zijn zonder een krachtige aan boord geïntegreerde processor.

Met de toename van edge computing, wat verwijst naar het uitvoeren van berekeningen op de mobiele apparaten zelf, wordt het gebruik van DevOps steeds populairder. Deze aanpak maakt een snelle levering van nieuw ontwikkelde functies aan consumenten mogelijk. Robots kunnen continu verbonden zijn met het netwerk en snel hun software bijwerken met behulp van Docker en andere in de praktijk bewezen tools.

Echter, extra mogelijkheden brengen extra risico's met zich mee - door computers de mogelijkheid te geven om intensief te interageren met de externe omgeving en tegelijkertijd met het internet, creëren we voorwaarden voor potentiële schade die deze apparaten kunnen veroorzaken als ze onder controle vallen van kwaadwillenden. Slimme apparaten, die geleidelijk onze huizen vullen, kunnen plotseling gek worden! Het aspect van beveiliging is hier van het grootste belang in een voortdurend veranderende wereld, omdat al deze apparaten zich dicht bij ons lichaam bevinden. Fouten kunnen te veel kosten.

Wat maakt robotica speciaal en onderscheidt het van andere computers? Deze speciale kenmerken omvatten:

1. Een verscheidenheid aan hardwareplatforms (in vergelijking met een relatief klein aantal soorten centrale processorarchitecturen)
2. Werken in onvoorspelbare omgevingen, wat de aanwezigheid van noodsituaties impliceert - bijvoorbeeld onbeschikbaarheid via communicatiekanalen
3. Beperkte middelen van aan boord geïntegreerde rekenapparaten - zwakke processor, relatief kleine hoeveelheid geheugen en lage netwerkbandbreedte4. Verhoogde veiligheidseisen
5. Een groot aantal apparaten dat updates en nieuwe functies vereist

Rekening houdend met deze beperkingen, zullen we proberen een conceptuele basis te formuleren voor DevOps voor robots op basis van Web3-technologieën, ten minste voor het schrijven van code, het bouwen en implementeren. We zullen proberen de meest interessante Web3-projecten te presenteren die in staat zijn om het functioneren van een gedecentraliseerde DevOps-conveyor te waarborgen en laten zien hoe Robonomics daar een integraal onderdeel van kan worden in de laatste fase van de levenscyclus - bij het implementeren van programma's in de externe wereld.

## Web3 en Blockchain

Wanneer we het hebben over Web3, bedoelen we in de eerste plaats Blockchain-technologie. Dit zijn natuurlijk nauw verwante concepten, maar niet precies identiek. Vaak wordt onder dit concept een hele reeks technologieën verstaan - elliptische krommencodering, P2P-netwerken, consensusalgoritme. De eerste twee punten zijn niets unieks en worden veel gebruikt in de IT-industrie, terwijl het laatste punt de blockchain echt voorziet van een speciale eigenschap, waardoor deze oplossing zo'n krachtig instrument wordt. Maar hebben we voor alle levenssituaties (en delen van de DevOps-conveyor) consensus nodig? Laten we proberen dit uit te zoeken.

Consensus heeft verschillende betekenissen in verschillende contexten, maar de essentie ervan is altijd hetzelfde - systemen, actoren of autonome agenten die deel uitmaken van een gedecentraliseerd netwerk komen overeen over welk protocol ze gebruiken in hun werk en de staat van gemeenschappelijke gegevens. Als de partijen niet tot een overeenkomst komen, leidt dit tot de zogenaamde Fork. Historisch gezien impliceerde een fork een splitsing van de blockchain, wat leidde tot de verdeling van de netwerknodes in twee delen - sommige nodes bleven "loyaal" aan de oude versie van het protocol, terwijl de rest overstapte naar de nieuwe versie. Dit evenement had altijd een negatieve context - de gemeenschap nam af in plaats van zich te consolideren, waardoor het project op de een of andere manier verzwakte. Tegelijkertijd, net als in de biologische evolutie, evenals in de technoversie die we nu waarnemen in de vorm van economie, treedt vertakking constant op en leidt bovendien tot het ontstaan van nieuwe levensvormen. Kijk naar de levensboom. Elke tak eraan is een Fork die in de oudheid plaatsvond - een mutatie bracht een nieuwe soort voort die onverenigbaar werd met zijn stamgenoten. Zonder dit mechanisme zou het leven in zijn moderne begrip onmogelijk zijn. Het is het vermogen van organismen om te muteren dat hen in staat stelt zich aan te passen aan veranderende omgevingsomstandigheden.

Zo komen we tot de conclusie dat consensus zowel goed is, omdat het de coördinatie van vele actoren mogelijk maakten and scalability, but at the same time it is bad, because it hinders the emergence of the new, as those who deviate from the consensus are always considered outcasts and the system kind of "pushes" them out.

Unlike biological evolution, we humans carry out techno-evolution, and it depends on us how this evolution takes place. The source of mutations in technology is engineers, applying the scientific method and creative thinking to produce new, more promising and viable versions of technology. We benefit from more frequent mutations, we benefit from decentralization in the sphere of generating new effective solutions both in relation to technology and organizations. On the contrary - a situation where one point of view "wins" and full and unconditional consensus is achieved, is fraught with the risk of collapse under certain circumstances. That is why nature did not go the way of creating super-organisms the size of a planet, but went the way of decentralization - when all living beings are scattered across ecological niches and ecosystems, which makes life as a whole stable and even stabilizes the planet Earth according to the [Daisyworld model](https://en.wikipedia.org/wiki/Daisyworld) (in short, thanks to the biosphere and its diversity, the planet becomes more stable).

So, why this digression? Primarily, I want to emphasize that not all data requires mandatory consensus, making blockchain inappropriate for every scenario. Consensus becomes necessary when uncoordinated actions could result in irreversible consequences. For instance, it's crucial at road intersections. If there's no agreement on traffic rules regarding when to go and when to stop, you can imagine the potential chaos!

Returning to the main topic of the article, it can be assumed that consensus is appropriate where the risks are high and, conversely, in cases where the risks are small, it is more appropriate to choose a completely decentralized system without consensus. Code development itself is a relatively safe activity, as long as it remains in the state of source or even executable files on the build server. However, when it comes to deploying these files in the physical infrastructure of the real world, it is very important to be consistent. That is why for the first two points of our DevOps stack (development and build) we chose like-minded projects without consensus.

## First Phase - Development - Radicle

![](/blog/images/web3-devops-stack/1st-phase-development.png)

So, in code development, complete freedom and decentralization are needed to stimulate thegeneratie van de beste oplossingen rechtstreeks van de auteurs. Gelukkig voor ons is in de code-ontwikkelingsindustrie de facto standaard een gedecentraliseerd op ontwerp gebaseerd versiebeheersysteem geworden. Ik heb het natuurlijk over git. git impliceert a priori niet de aanwezigheid van een enkele "bron van waarheid" - elke gebruiker moet het repository klonen naar hun computer en werken met hun lokale kopie voordat ze de code gebruiken. Bovendien is de gegevensopslagmethode in git niets meer dan een keten van blokken (vaste feiten van codeveranderingen - commits), die de onveranderlijkheid van de geschiedenis garanderen. Met andere woorden, git zelf is een soort blockchain, waarvan de consensus handmatig wordt bereikt door de auteurs zelf via branching en merge-verzoeken.

Desondanks, ondanks de gedecentraliseerde aard van git, hebben web2-platforms hun plaats ingenomen. Nu is code-ontwikkeling bijna volledig gecentraliseerd rond een relatief klein aantal platforms zoals Github, Bitbucket, Gitlab. En dit gebeurde precies vanwege de introductie van aanvullende tools: DevOps (CI/CD-pipelines, ingebouwde functies voor het detecteren van kwetsbaarheden in afhankelijkheden van broncode en nog veel meer) en Sociale Netwerken (beloningssystemen voor ontwikkelaars, probleemopsporing, projectbeheer). Deze tools maken geen deel uit van het oorspronkelijke git-protocol en bemoeilijken de migratie van projecten van platform naar platform.

Het project [Radicle](https://radicle.xyz/) is opgericht met als doel code-ontwikkelaars te bevrijden van de noodzaak om afhankelijk te zijn van grote platforms, die wij beschouwen als het eerste component van onze Web3-DevOps-stack. Het project heeft een vrij [lange geschiedenis](https://docs.radworks.org/community/our-story) en een aantal significante transformaties op weg naar het huidige moment. Aanvankelijk was Radicle gebouwd bovenop het destijds populair wordende Inter Planetary File System (IPFS), maar op een gegeven moment realiseerden ontwikkelaars zich dat de manieren om code-repositorygegevens op te slaan en te hashen in IPFS niet compatibel waren met de manieren van opslaan in git, wat leidde tot duplicatie van informatie en overmatig dataverkeer zelfs in het geval van kleine updates. Geleidelijk werd besloten over te stappen op een meer minimalistische oplossing - om git-patches rechtstreeks uit te wisselen, met gebruik van het native [pack-protocol](https://git-scm.com/docs/pack-protocol/en), om dit de belangrijkste manier van gegevensoverdracht in het "codekeeper"-netwerk te maken. Deze beslissing diende als het begin van een grote refactoring en herschrijven van het project van Go naar Rust. De nieuwe versie van het protocol, genaamd Heartwood,haalt inspiratie uit projecten zoals Secure Scuttlebutt (SSB) en het [Lightning Network](https://en.wikipedia.org/wiki/Lightning_Network) van Bitcoin.

Later, in 2021, werd de Gedecentraliseerde Autonome Organisatie (of simpelweg DAO) Radworks opgericht op de Ethereum blockchain, werd het RAD governance token uitgegeven en werden de benodigde fondsen ingezameld voor verdere ontwikkeling van het project. Blijkbaar ontkent het projectteam niet het belang van sociale en economische componenten bij codeontwikkeling, maar probeert tegelijkertijd niet alle ondersteunende tools te integreren in hun implementatie. Een van deze initiatieven is hun project en gelijknamige slimme contract [Drips](https://www.drips.network/), dat gericht is op de automatische verdeling van donaties onder open source ontwikkelaars onder het motto "Financier uw afhankelijkheden". Binnen dit slimme contract kan elk ontwikkelingsproject automatische herverdeling van ontvangen donaties instellen voor zijn set van afhankelijkheden (pakketten, bibliotheken).

Zeer recentelijk, in maart 2024, werd de 1.0.0 release van de implementatie van het Heartwood-protocol uitgebracht, wat betekent dat het al kan worden overwogen voor productiescenario's van gedecentraliseerde ontwikkelingspijplijnen.

## Tweede Fase - Bouwen, Testen, Continue Integratie - Fluence

![web3 software bouwen](/blog/images/web3-devops-stack/2nd-phase-build.png)

De volgende stap in onze vereenvoudigde DevOps-pijplijn is de bouwfase, die meer omvat dan alleen codecompilatie. Het omvat een reeks processen met variërende computationele resource-intensiteiten. Deze berekeningen leiden echter niet altijd tot tastbare veranderingen. Met andere woorden, niet elke codeverandering of bouwinitiatief resulteert in een release. Vaak worden Continuous Integration (CI) pijplijnen op een schema uitgevoerd. De artefacten die ze produceren zijn meestal van korte duur en worden verwijderd als ze niet zijn opgenomen in een release. Daarom beschouwen we deze fase in de ontwikkelingslevenscyclus niet als consensus vereisend, vergelijkbaar met tal van cloud computing projecten die blockchain gebruiken voor resultaatverificatie.

De ontwikkelaars van [Fluence](https://fluence.dev/) hebben een vergelijkbare positie. Dit is een project dat zeer dicht bij Robonomics staat, dat ook intensief gebruik maakt van libP2P als transportlaag en ipfs als opslaglaag in zijn use cases, terwijl het zich richt op de orchestratie van peers en berekeningen op hen zonder de noodzaak van gecentraliseerde platforms. Laten we ze eens nader bekijken.

Fluence bestaat uit twee belangrijke componenten - Aqua en Marine. De eerste is een domeinspecifieke taal (DSL) en wordt gebruikt om de reeks taken te beheren.op rekenapparaten, d.w.z. om peers te orchestreren. Aan de ene kant kan het beheersen van een andere taal veel gebruikers afschrikken, aan de andere kant is het een eerlijke stap die je meteen voorbereidt op de onvermijdelijke toekomst. Het feit is dat de meeste CI-platforms meestal configuratiebestanden aanbieden in enkele gangbare formaten zoals YAML of JSON voor het beheren en instellen van pipelines. In het begin is dit echt handig en stelt het elke gebruiker zonder programmeervaardigheden in staat om aan de slag te gaan, maar na verloop van tijd, naarmate de behoeften en, dienovereenkomstig, het aantal configuraties groeien, leidt het gebrek aan zo vertrouwde tools voor programmeurs tot de groei van boilerplate code en het onvermogen om complexiteit te beheren. Pogingen om van YAML een configuratietaal te maken met behulp van sjablonen lossen het probleem ook niet op, wat bijdraagt aan het ontstaan van Ad-hoc configuratiebeschrijvingstalen zoals HCL (HashiCorp Configuration Language). Aqua biedt een onmiddellijke oplossing in de vorm van een toepassingsprogrammeertaal voor de stroom van berekeningen, die een betrouwbare theoretische basis heeft in de vorm van Pi-calculus, waarin Aqua-code wordt gecompileerd voor verdere uitvoering op peers. Dit verhoogt de instapdrempel in de technologie een beetje, maar zou idealiter meer stabiel en onderhoudbaar werk in de toekomst moeten bieden. Op dit moment is Aqua een vrij laag-niveau taal, maar na verloop van tijd kunnen er bibliotheken verschijnen die best practices implementeren voor het ontwerpen van computationele stromen met behulp van handige wiskundige abstracties, wat de ontwikkeling van gedistribueerde berekeningen zal versnellen.

Aqua bepaalt de volgorde van berekeningen, maar de berekeningen zelf worden voorbereid en uitgevoerd met behulp van Marine - een component die ook is ontwikkeld door Fluence. Marine is een SDK (Software Developers Kit) - een set tools voor het samenstellen van onderling compatibele Webassembly-modules, evenals een Runtime - een algemene omgeving voor hun uitvoering. Modules zijn relatief onafhankelijke softwarecomponenten, elk met zijn eigen staat, maar kunnen met elkaar communiceren via functie-import/export. Een set van elkaar beïnvloedende modules vormt een service, die complex gedrag implementeert en fungeert als een actor in het Fluence peer-netwerk.

Samen bieden Aqua en Marine volledig wat kan worden genoemd het denken van een cyber-fysiek systeem - dat wil zeggen, alle variëteit aan berekeningen die helpen beslissingen te nemen over welke acties te ondernemen in de buitenwereld om de kansen op succes in de evolutionaire race te vergroten.

[Modelgebaseerde](https://en.wikipedia.org/wiki/Model-based_systems_engineering) ontwikkeling van robotica vereist resource-intensieve berekeningen. Een aanzienlijk deel van de tests van de ontwikkelde software voor robots wordt uitgevoerd in simulatoren, en op versterking gebaseerde leeralgoritmen starten dergelijke virtuele omgevingen honderdduizenden.van keren voordat ze het gewenste gedrag van de agent bereiken. Diverse natuurkunde- en renderingsengines, evenals op hen gebaseerde game-engines, kunnen dienen als virtuele omgevingen. Onlangs is het ontwerppatroon Entity Component System wijdverspreid geworden in deze omgevingen. Overigens maakt de moderne versie van de bekende, maar beperkt bekende, robot simulator Gazebo/ex-Ignition van Open Robotics (zij ontwikkelen ook ROS) ook [gebruik van ECS](https://gazebosim.org/docs/harmonic/architecture) om de prestaties en flexibiliteit te verhogen. Volgens de ontwikkelaars van Fluence is hun uitvoeringsmodel in feite zeer geschikt voor de implementatie van gedistribueerde architecturen die op dit principe zijn gebouwd.

Natuurlijk moet software die gecompileerd en getest is waarde toevoegen door te worden geïmplementeerd op hardwareplatforms. Hypothetisch gezien is het ook mogelijk om software te implementeren met behulp van Fluence. De ontwikkelaars zelf zeggen dat hun stack ook implementatie op peers mogelijk maakt, en dat is inderdaad het geval. Wij zijn echter van mening dat consensus nodig en belangrijk is op het gebied van interactie met de externe omgeving en fysieke apparatuur.

## Derde Fase - Implementatie - Robonomics

![robotica implementatie kunst](/blog/images/web3-devops-stack/3rd-phase-deploy.png)

Een belangrijke eigenschap van software is het feit dat het op zichzelf de buitenwereld niet verandert, maar dient als een model van de omringende realiteit en helpt om erover te redeneren - hypotheses op te stellen, een actieplan voor te stellen, processen in de buitenwereld op gang te brengen met behulp van apparatuur of mensen. Een probleemtracker is bijvoorbeeld zelf geen systeem dat de buitenwereld verandert, het kan worden beschouwd als een digitale tweeling van het ontwikkelingsteam, dat op zijn beurt veranderingen in het leven brengt. Dankzij de probleemtracker kan het team acties coördineren met elkaar, elkaar helpen. Met andere woorden, de probleemtracker maakt het mogelijk om consensus te bereiken binnen het ontwikkelingsteam - wie doet welke taken en wanneer - maar de verandering zelf wordt door mensen gemaakt.

Bij het bespreken van wereldveranderende systemen verwijzen we naar fysieke entiteiten die opereren in de echte wereld, zoals slimme apparaten, robots en autonome fabrieken. In wezen fungeert Robonomics als een brug van informatiesystemen en mensen naar de externe wereld via robotische systemen. Het belang van veiligheid kan niet genoeg worden benadrukt, aangezien het verwaarlozen ervan niet alleen tot kapitaalverliezen kan leiden, maar ook tot echte rampen.

Ondanks de kritieke aard van deze systemen verschenen de eerste veilige gedecentraliseerde opslagsystemen niet in de industriële sector, maar in de financiële sector. Bankrekeningen bleken teEen aantrekkelijker doelwit voor computercriminelen dan huishoudelijke apparaten, waarvan de meeste geen netwerkverbinding hadden. De technologie die wordt gebruikt om bankinformatiesystemen te beveiligen, is aanzienlijk geëvolueerd, van SWIFT tot Ethereum, en wordt nu geleidelijk geïmplementeerd in andere economische sectoren.

Robonomics staat aan de voorhoede van deze veilige, gedecentraliseerde netwerken en neemt de leiding over de laatste fase van de Web3 DevOps-conveyor - implementatie.

In algemene termen is een implementatie het in bedrijf stellen van een systeem. Een meer bekend synoniem voor deze term is installatie - een gebeurtenis waarbij het geproduceerde en geleverde systeem (een exemplaar van een bepaald type apparatuur, een uitvoerbaar bestand van software) begint te functioneren binnen een systeem op een hoger niveau. Wat is goed aan blockchain in dit geval? Allereerst is het altijd belangrijk voor ons om te begrijpen wat er precies is vrijgegeven wanneer we een versie van het programma naar buiten brengen. Tijdens de ontwikkeling kunnen versies zeer vaak veranderen en dat is normaal, dus het is niet raadzaam om alle informatie over hen in de blockchain te plaatsen. Echter, de gebeurtenis van vrijgave of lancering moet worden vastgelegd, zodat we bij het ontvangen van feedback duidelijk kunnen begrijpen met welke exacte versie van broncodes of tekeningen we deze feedback moeten vergelijken. De blockchain kan dienen als een betrouwbaar repository van informatie over alle software-updates van apparaten die ermee verbonden zijn.

Bovendien moet het installatieproces consistent zijn, omdat afwijkingen kunnen leiden tot configuratieconflicten. Deze conflicten kunnen ontstaan door het niet overeenkomen van softwaremoduleversies, het implementeren van verschillende systemen binnen dezelfde ruimte en andere gerelateerde problemen. Bijvoorbeeld, de eerder genoemde auto-ongeluk op een ongereguleerd kruispunt is een voorbeeld van zo'n botsing. In de context van software-implementatie kunnen botsingen zich manifesteren als API-overtredingen, onvoldoende hardwarecapaciteiten of schrijven naar verboden of onveilige geheugenlocaties. Robonomics kan de configuraties van verbonden apparatuur opslaan en op het niveau van het consensusalgoritme dergelijke toestanden voorkomen.

Je kunt een speciale [lancering](https://wiki.robonomics.network/docs/launch/) oproepen om software in de Robonomics parachain te implementeren, waarmee je een node kunt starten die is verbonden met de blockchain met aanvullende parameters. De parameter kan een unieke identificatie zijn in het IPFS-contentdistributienetwerk, waaruit je een softwarebeeld, een binair bestand, broncode voor de configuratie van het besturingssysteem of zelfs een bash-script kunt halen! Aangezien elke transactie in het netwerk is ondertekend met een cryptografische sleutel, is zo'n oproep in de parachain in wezen gelijk aan een openbare releasesignatuur.

Voor meer complexe scenario's kun je een [digitaal tweeling](https://wiki.robonomics.network/docs/digital-twins/), waarmee een overeenkomstentabel kan worden ingesteld tussen willekeurige gegevens van 256 bits lang en een account in het Robonomics-netwerk. Op deze manier kunt u een logboek bijhouden van configuratieversie wijzigingen voor apparaataccounts in het Robonomics-netwerk. In traditionele configuratie- en implementatiesystemen worden hosts meestal gespecificeerd als knooppunten - dit zijn computers met een DNS-naam of IP-adres. In het geval van Web3 worden hosts geïdentificeerd dankzij hun openbare cryptografische sleutels, waaraan accounts zijn gekoppeld. Om de configuratie te wijzigen, kunt u een nieuwe inhoudsidentificator toevoegen, waarvan het apparaat een nieuwe versie van de software zal ontvangen en bijwerken.

## Alles samenvoegen

![web3 devops stack](/blog/images/web3-devops-stack/devop-stack-full-art.png)

Laten we dus proberen dit vanuit een vogelperspectief te bekijken. Mensen vormen de kern van ons grote cyber-fysieke systeem. Mensen zijn chaotisch, onvoorspelbaar... en dat is goed! Ze genereren nieuwe betekenissen, ideeën, producten. Ze actualiseren hun wil om de wereld te veranderen. Nu is het in de 21e eeuw niet nodig om de wereld met eigen handen te veranderen. Er liggen taken voor de mensheid waarvoor menselijke handen niet het meest geschikte gereedschap zijn. In plaats daarvan zijn er machines, die nu dienen als de dirigent van onze wil. Machines daarentegen zijn strikt deterministisch en voorspelbaar. En mensen houden daarvan, ja. Ze vinden het fijn als de trein op tijd op het station aankomt, en de kwaliteit van de producten die ze consumeren altijd voorspelbaar uitstekend is. Hiervoor gebruiken mensen netwerken. Veel netwerken! Ze genereren ideeën op het Radicle-netwerk, machines verzamelen en testen ze tot uitvoerbare modules op het Fluence-netwerk, en implementeren ze vervolgens op robots op het Robonomics-netwerk. De robots transformeren op hun beurt de omgeving, en hun sensoren, ook via Robonomics, geven feedback aan mensen om een beslissing te nemen - de cyclus is gesloten. Dit is een cyclus van voortdurende verbeteringen, waar iedereen zijn plaats heeft. Er is geen tegenstelling tussen de machine en de mens - beide creëren in harmonie een nieuwe orde van de mensheid - interplanetaire mensheid.