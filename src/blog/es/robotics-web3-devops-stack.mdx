---
title: Pila Tecnológica de Desarrollo Web3 de Robótica
date: 2024-06-12
published: true
locale: 'es'
tags: ['DevOps', 'Web3']
cover_image: /blog/images/web3-devops-stack/web3-devops-stack-Cover.png
description: "El movimiento DevOps ha revolucionado el mundo de la tecnología de la información y ha remodelado nuestra comprensión de la mejora continua y efectiva de sistemas. El campo de la robótica apenas está comenzando a explorar este enfoque. En este artículo, visualizamos el futuro potencial de DevOps para la robótica utilizando tecnologías Web3. También destacamos algunos proyectos que podrían sentar las bases para este futuro."
abstract: "El movimiento DevOps ha revolucionado el mundo de la tecnología de la información y ha remodelado nuestra comprensión de la mejora continua y efectiva de sistemas. El campo de la robótica apenas está comenzando a explorar este enfoque. En este artículo, visualizamos el futuro potencial de DevOps para la robótica utilizando tecnologías Web3. También destacamos algunos proyectos que podrían sentar las bases para este futuro."
---

## Orígenes del Desarrollo y Operaciones

Los robots, como dispositivos que se mueven y perciben el mundo externo, son un caso específico de computadoras. Como suelen decir los ingenieros, un avión es una computadora voladora, enfatizando la importancia del dispositivo informático a bordo para mantener la viabilidad de este sistema ciberfísico. Por lo tanto, podemos observar cómo el mundo de los sistemas de información ha evolucionado en el siglo XXI e identificar ciertas tendencias que serán inherentes a la robótica en un futuro muy cercano.

El software y las prácticas utilizadas para su desarrollo han cambiado significativamente los enfoques de trabajo tanto en ingeniería como en cualquier otra actividad. En primer lugar, los cambios afectaron al llamado enfoque en cascada, cuando cualquier proyecto se veía como una serie de largas etapas alternas: Requisitos - Desarrollo - Verificación - Validación - Operación. Con el tiempo, se descubrió que la división en etapas es conveniente para los gerentes, pero no corresponde del todo a cómo sucede en la vida y complica la adaptación rápida de los productos en condiciones de un mundo externo en constante cambio. Las metodologías ágiles, que implican un trabajo sincrónico en el proyecto con pequeños intervalos de planificación, vinieron a reemplazar el modelo en cascada de actividad (y gestión). En lugar de grandes etapas con hitos, hubo pequeñas iteraciones con incrementos: cambios pequeños pero frecuentes en los sistemas desarrollados con una rápida implementación. Este ritmo de trabajo es inalcanzable si la implementación está acompañada de procedimientos administrativos complejos con verificaciones manuales. Así surgió el movimiento de Desarrollo y Operaciones para implementar prácticas de transferencia de valor de los desarrolladores a los consumidores sin pérdidas y una nueva profesión de un DevOps.Ingeniero de operaciones, automatizando el proceso de poner rápidamente en funcionamiento el sistema.

![orígenes de DevOps](/blog/images/web3-devops-stack/devops-evolution.png)

Estas prácticas incluyen pruebas automatizadas, integración continua, entrega, implementación y monitoreo de software. Las pruebas automatizadas verifican errores, mientras que la integración continua integra cambios de código con frecuencia para detectar problemas temprano. La entrega e implementación implican llevar el software a los usuarios e instalarlo en su entorno.

Inicialmente, estas prácticas cobraron impulso en el área de los grandes servicios web, que sirven a millones de usuarios en todo el mundo. En dicho contexto, estas prácticas son cruciales para mantener el alto rendimiento y la confiabilidad esperados de tales servicios. Sin embargo, a medida que ha avanzado el tiempo y las herramientas de automatización se han vuelto más accesibles (en parte debido a las contribuciones de código abierto), DevOps ha comenzado a utilizarse en actividades de ingeniería más tradicionales. Por lo tanto, estas prácticas han trascendido su dominio inicial y ahora se emplean en diversos sectores para mejorar la eficiencia, confiabilidad y calidad de los productos de software.

## Características Clave de los Robots en el Contexto de DevOps

Los robots, a diferencia de los servidores estacionarios y los centros de datos, se mueven en el espacio y perciben el entorno externo. Cada vez más de estos dispositivos están surgiendo. Vemos cómo su potencia computacional crece con el tiempo: muchas soluciones técnicas simplemente serían imposibles sin un potente procesador a bordo.

Con el aumento de la informática en el borde, que se refiere a la informática en los propios dispositivos móviles, el uso de DevOps se está volviendo más popular. Este enfoque permite la entrega rápida de nuevas funciones desarrolladas a los consumidores. Los robots pueden estar continuamente conectados a la red y actualizar rápidamente su software utilizando Docker y otras herramientas probadas en la práctica.

Sin embargo, capacidades adicionales crean riesgos adicionales: al capacitar a las computadoras con la capacidad de interactuar intensamente con el entorno externo e Internet simultáneamente, creamos condiciones para el daño potencial que estos dispositivos pueden causar si caen bajo el control de malhechores. ¡Los dispositivos inteligentes, que gradualmente llenan nuestros hogares, pueden volverse locos de repente! El tema de la seguridad aquí es de suma importancia en un mundo en constante cambio, porque todos estos dispositivos están en estrecha proximidad a nuestros cuerpos. Los errores pueden costar demasiado.

¿Qué hace que la robótica sea especial y la distingue de otras computadoras? Estas características especiales incluyen:

1. Una variedad de plataformas de hardware (en comparación con un número relativamente pequeño de tipos de arquitectura de procesadores centrales)
2. Trabajar en entornos impredecibles, lo que implica la presencia de situaciones de emergencia, como la falta de disponibilidad en los canales de comunicación
3. Recursos limitados de los dispositivos informáticos a bordo: procesador débil, cantidad relativamente pequeña de memoria y ancho de banda de red bajo4. Requisitos de seguridad aumentados
5. Un gran número de dispositivos que requieren actualizaciones y nuevas características

Teniendo en cuenta estas restricciones, intentaremos formular una base conceptual para DevOps para robots basada en tecnologías Web3, al menos, para escribir código, construir e implementar. Intentaremos presentar los proyectos Web3 más interesantes capaces de garantizar el funcionamiento de un transportador de DevOps descentralizado y mostrar cómo Robonomics puede convertirse en una parte integral de él en la fase final del ciclo de vida, al implementar programas en el mundo externo.

## Web3 y Blockchain

Cuando hablamos de Web3, principalmente nos referimos a la tecnología Blockchain. Estos son conceptos estrechamente relacionados, pero no exactamente idénticos. A menudo, bajo este concepto se implica todo un conjunto de tecnologías: criptografía de curva elíptica, redes P2P, algoritmo de consenso. Los dos primeros puntos no son algo único y se utilizan ampliamente en la industria de TI, mientras que el último realmente dota a la cadena de bloques de una característica especial, convirtiendo esta solución en una herramienta tan poderosa. Pero, ¿necesitamos consenso para todas las situaciones de la vida (y partes del transportador DevOps)? Intentemos entenderlo.

El consenso tiene diferentes significados en diferentes contextos, pero su esencia siempre es la misma: los sistemas, actores o agentes autónomos que conforman una red descentralizada llegan a un acuerdo sobre qué protocolo utilizar en el trabajo y el estado de los datos comunes. Si las partes no llegan a un acuerdo, esto conduce a la llamada bifurcación. Históricamente, una bifurcación implicaba una división de la cadena de bloques, lo que llevaba a la división de los nodos de la red en dos partes: algunos nodos permanecían "leales" a la versión antigua del protocolo, mientras que el resto pasaba a la nueva versión. Este evento siempre tenía un contexto negativo: la comunidad disminuía en lugar de consolidarse, lo que debilitaba de alguna manera el proyecto. Al mismo tiempo, como en la evolución biológica, así como en su versión tecnológica que observamos ahora en forma de economía, la ramificación ocurre constantemente y, además, conduce a la aparición de nuevas formas de vida. Mira el árbol de la vida. Cada rama en él es una bifurcación que ocurrió en tiempos antiguos: una mutación dio origen a una nueva especie que se volvió incompatible con sus congéneres. Sin este mecanismo, la vida en su entendimiento moderno sería imposible. Es la capacidad de los organismos de mutar lo que les permite adaptarse a las cambiantes condiciones ambientales.

Así, llegamos a la conclusión de que el consenso es algo bueno, porque permite la coordinación de muchos actoresy la escalabilidad, pero al mismo tiempo es malo, porque obstaculiza la emergencia de lo nuevo, ya que aquellos que se desvían del consenso siempre son considerados marginados y el sistema de alguna manera los "empuja" hacia afuera.

A diferencia de la evolución biológica, nosotros los humanos llevamos a cabo la tecno-evolución, y depende de nosotros cómo se lleva a cabo esta evolución. La fuente de mutaciones en la tecnología son los ingenieros, que aplican el método científico y el pensamiento creativo para producir versiones nuevas, más prometedoras y viables de la tecnología. Nos beneficiamos de mutaciones más frecuentes, nos beneficiamos de la descentralización en la esfera de generar nuevas soluciones efectivas tanto en tecnología como en organizaciones. Por el contrario, una situación en la que un punto de vista "gana" y se logra un consenso completo e incondicional, conlleva el riesgo de colapso en ciertas circunstancias. Por eso la naturaleza no siguió el camino de crear superorganismos del tamaño de un planeta, sino que siguió el camino de la descentralización, cuando todos los seres vivos están dispersos en nichos ecológicos y ecosistemas, lo que hace que la vida en su conjunto sea estable e incluso estabiliza el planeta Tierra según el [modelo Daisyworld](https://es.wikipedia.org/wiki/Daisyworld) (en resumen, gracias a la biosfera y su diversidad, el planeta se vuelve más estable).

Entonces, ¿por qué esta digresión? Principalmente, quiero enfatizar que no todos los datos requieren un consenso obligatorio, lo que hace que la cadena de bloques sea inapropiada para todos los escenarios. El consenso se vuelve necesario cuando las acciones no coordinadas podrían resultar en consecuencias irreversibles. Por ejemplo, es crucial en las intersecciones de carreteras. ¡Si no hay acuerdo sobre las reglas de tráfico respecto a cuándo avanzar y cuándo detenerse, puedes imaginar el caos potencial!

Volviendo al tema principal del artículo, se puede suponer que el consenso es apropiado donde los riesgos son altos y, por el contrario, en casos donde los riesgos son pequeños, es más apropiado elegir un sistema completamente descentralizado sin consenso. El desarrollo de código en sí es una actividad relativamente segura, siempre y cuando permanezca en estado de código fuente o incluso archivos ejecutables en el servidor de compilación. Sin embargo, cuando se trata de implementar estos archivos en la infraestructura física del mundo real, es muy importante ser coherente. Por eso, para los dos primeros puntos de nuestra pila de DevOps (desarrollo y compilación) elegimos proyectos afines sin consenso.

## Primera Fase - Desarrollo - Radicle

![](/blog/images/web3-devops-stack/1st-phase-development.png)

Entonces, en el desarrollo de código, se necesita completa libertad y descentralización para estimular lageneración de las mejores soluciones directamente de los autores. Afortunadamente para nosotros, en la industria del desarrollo de código, el estándar de facto se ha convertido en un sistema de control de versiones descentralizado por diseño. Estoy hablando, por supuesto, de git. git a priori no implica la presencia de una única "fuente de verdad": cualquier usuario, antes de usar el código, necesita clonar el repositorio en su computadora y trabajar con su copia local. Además, el método de almacenamiento de datos en git no es más que una cadena de bloques (hechos fijos de cambios de código - commits), que garantizan la inmutabilidad de la historia. Es decir, git en sí mismo es una especie de blockchain, cuyo consenso se logra manualmente por los propios autores a través de ramificaciones y solicitudes de fusión.

Sin embargo, a pesar de la naturaleza descentralizada de git, las plataformas web2 han tomado su lugar. Ahora, el desarrollo de código está casi completamente centralizado en torno a un número relativamente pequeño de plataformas como Github, Bitbucket, Gitlab. Y esto sucedió precisamente debido a la introducción de herramientas adicionales: DevOps (pipelines de CI/CD, funciones integradas para detectar vulnerabilidades en las dependencias del código fuente y mucho más) y Redes Sociales (sistemas de recompensa para desarrolladores, seguimiento de problemas, gestión de proyectos). Estas herramientas no forman parte del protocolo git original y complican la migración de proyectos de una plataforma a otra.

El proyecto [Radicle](https://radicle.xyz/) fue fundado específicamente con el objetivo de liberar a los desarrolladores de código de la necesidad de depender de grandes plataformas, que consideramos como el primer componente de nuestra pila Web3-DevOps. El proyecto tiene una [historia bastante larga](https://docs.radworks.org/community/our-story) y una serie de transformaciones significativas en su camino hacia su momento actual. Inicialmente, Radicle se construyó sobre el entonces creciente Sistema de Archivos Interplanetario (IPFS), pero en algún momento los desarrolladores se dieron cuenta de que las formas de almacenar y hashear los datos del repositorio de código en IPFS eran incompatibles con las formas de almacenar en git, lo que llevaba a la duplicación de información y al consumo excesivo de tráfico incluso en el caso de pequeñas actualizaciones. Gradualmente, se tomó la decisión de cambiar a una solución más minimalista: intercambiar parches de git directamente, utilizando el protocolo nativo [pack protocol](https://git-scm.com/docs/pack-protocol/en), para hacer de esta la principal forma de transmisión de datos en la red "codekeeper". Esta decisión sirvió como el comienzo de una importante refactorización y reescritura del proyecto de Go a Rust. La nueva versión del protocolo, llamada Heartwood,se inspira en proyectos como Secure Scuttlebutt (SSB) y la [Red Lightning](https://es.wikipedia.org/wiki/Red_Lightning) de Bitcoin.

Más tarde, en 2021, se fundó la Organización Autónoma Descentralizada (o simplemente DAO) Radworks en la cadena de bloques de Ethereum, se emitió el token de gobernanza RAD y se recaudaron los fondos necesarios para el desarrollo continuo del proyecto. Aparentemente, el equipo del proyecto no niega la importancia de los componentes sociales y económicos en el desarrollo de código, pero al mismo tiempo no intenta integrar todas las herramientas de apoyo en su implementación. Una de esas iniciativas es su proyecto y contrato inteligente homónimo [Drips](https://www.drips.network/), que tiene como objetivo la distribución automática de donaciones entre desarrolladores de código abierto bajo el lema "Financia tus dependencias". Dentro de este contrato inteligente, cada proyecto de desarrollo puede configurar la redistribución automática de las donaciones recibidas para su conjunto de dependencias (paquetes, bibliotecas).

Recientemente, en marzo de 2024, se lanzó la versión 1.0.0 de la implementación del protocolo Heartwood, lo que significa que ya se puede considerar para escenarios de producción de canalizaciones de desarrollo descentralizado.

## Segunda Fase - Construcción, Pruebas, Integración Continua - Fluence

![construcción de software web3](/blog/images/web3-devops-stack/2nd-phase-build.png)

El siguiente paso en nuestra canalización simplificada de DevOps es la etapa de construcción, que incluye más que simplemente la compilación de código. Involucra una serie de procesos con diferentes intensidades de recursos computacionales. Sin embargo, estas computaciones no siempre conducen a cambios tangibles. En otras palabras, no cada cambio de código o inicio de construcción resulta en un lanzamiento. A menudo, las canalizaciones de Integración Continua (CI) se ejecutan según un horario. Los artefactos que producen suelen tener una vida corta y se eliminan si no se incluyen en un lanzamiento. Por lo tanto, no consideramos esta etapa en el ciclo de vida de desarrollo como que requiera consenso, similar a numerosos proyectos de computación en la nube que utilizan blockchain para la verificación de resultados.

Los desarrolladores de [Fluence](https://fluence.dev/) mantienen una posición similar. Este es un proyecto muy cercano a Robonomics, que también utiliza intensivamente libP2P como capa de transporte e ipfs como capa de almacenamiento en sus casos de uso, centrándose en la orquestación de pares y cálculos en ellos sin necesidad de plataformas centralizadas. Veamos más de cerca.

Fluence consta de dos componentes clave: Aqua y Marine. El primero es un lenguaje específico de dominio (DSL) y se utiliza para gestionar la secuencia de tareas:

## Flujo de Computación en Dispositivos de Cómputo"

En los dispositivos de cómputo, es decir, para orquestar pares. Por un lado, dominar otro idioma puede disuadir a muchos usuarios, por otro lado, es un paso honesto que te prepara de inmediato para el futuro inevitable. La realidad es que la mayoría de las plataformas de CI suelen ofrecer archivos de configuración en algunos formatos comunes como YAML o JSON para gestionar y configurar pipelines. Al principio, esto es realmente conveniente y permite que cualquier usuario sin habilidades de programación comience a trabajar, pero con el tiempo, a medida que las necesidades y, en consecuencia, la cantidad de configuraciones crecen, la falta de herramientas tan familiares para los programadores conduce al crecimiento del código redundante y la incapacidad de gestionar la complejidad. Los intentos de hacer de YAML un lenguaje de configuración utilizando plantillas tampoco resuelven el problema, lo que contribuye a la aparición de lenguajes de descripción de configuración Ad-hoc como HCL (HashiCorp Configuration Language). Aqua ofrece una solución inmediata en forma de un lenguaje de programación de aplicaciones para el flujo de cálculos, que tiene una base teórica confiable en forma de cálculo Pi, en el que se compila el código Aqua para su posterior ejecución en pares. Esto hace que el umbral de entrada a la tecnología sea un poco más alto, pero idealmente debería proporcionar un trabajo más estable y mantenible en el futuro. Actualmente, Aqua es un lenguaje bastante de bajo nivel, pero con el tiempo pueden aparecer bibliotecas que implementen las mejores prácticas para diseñar flujos de cálculo utilizando abstracciones matemáticas convenientes, lo que acelerará el desarrollo de cálculos distribuidos.

Aqua establece el orden de los cálculos, pero los cálculos mismos se preparan y se llevan a cabo utilizando Marine, un componente también desarrollado por Fluence. Marine es un SDK (Kit de Desarrollo de Software) - un conjunto de herramientas para ensamblar módulos de Webassembly mutuamente compatibles, así como un Runtime - un entorno de propósito general para su ejecución. Los módulos son componentes de software relativamente independientes, cada uno de los cuales almacena su propio estado, pero pueden interactuar entre sí a través de la importación/exportación de funciones. Un conjunto de módulos que interactúan forma un servicio, que implementa un comportamiento complejo y actúa como un actor en la red de pares de Fluence.

Juntos, Aqua y Marine proporcionan completamente lo que se puede llamar el pensamiento de un sistema ciberfísico, es decir, toda la variedad de cálculos que ayudan a tomar decisiones sobre qué acciones tomar en el mundo exterior para aumentar las posibilidades de éxito en la carrera evolutiva.

El desarrollo de robótica basado en modelos requiere cálculos intensivos en recursos. Una parte significativa de las pruebas del software desarrollado para robots se realizan en simuladores, y los algoritmos basados en aprendizaje por refuerzo lanzan estos entornos virtuales cientos de miles de veces antes de lograr el comportamiento deseado del agente. Varios motores de física y renderizado, así como los motores de juego basados en ellos, pueden servir como entornos virtuales. Recientemente, el patrón de diseño del Sistema de Componentes de Entidad se ha vuelto ampliamente utilizado en estos entornos. Por cierto, la versión moderna del conocido simulador robótico Gazebo/ex-Ignition de Open Robotics (ellos también desarrollan ROS) también [utiliza ECS](https://gazebosim.org/docs/harmonic/architecture) para aumentar el rendimiento y la flexibilidad. De hecho, según los desarrolladores de Fluence, su modelo de ejecución es adecuado para la implementación de arquitecturas distribuidas basadas en este principio.

Por supuesto, para que el software compilado y probado aporte valor, debe implementarse en plataformas de hardware. Hipotéticamente, también es posible implementar software utilizando Fluence. De hecho, los propios desarrolladores afirman que su conjunto de herramientas también permite la implementación en pares, y esto es realmente cierto. Sin embargo, creemos que se necesita consenso e importancia en el área de interacción con el entorno externo y el equipo físico.

## Tercera Fase - Implementación - Robonomics

![arte de implementación de robótica](/blog/images/web3-devops-stack/3rd-phase-deploy.png)

Una característica importante del software es el hecho de que no cambia el mundo exterior por sí mismo, sino que sirve como un modelo de la realidad circundante y ayuda a razonar sobre ella, construir hipótesis, proponer un plan de acción, iniciar procesos en el mundo exterior utilizando equipos o personas. Por ejemplo, un rastreador de problemas en sí mismo no es un sistema que cambie el mundo exterior, se puede llamar un gemelo digital del equipo de desarrollo, que a su vez lleva a cabo cambios en la vida real. Gracias al rastreador de problemas, el equipo puede coordinar acciones entre sí, ayudarse mutuamente. En otras palabras, el rastreador de problemas permite mantener un consenso dentro del equipo de desarrollo: quién hace qué tareas y cuándo, pero el cambio en sí lo realizan las personas.

Al discutir sistemas que cambian el mundo, nos referimos a entidades físicas que operan en el mundo real, como dispositivos inteligentes, robots y fábricas autónomas. Esencialmente, Robonomics sirve como un puente entre los sistemas de información y las personas con el mundo exterior a través de sistemas robóticos. La importancia de la seguridad no puede ser subestimada, ya que descuidarla podría llevar no solo a pérdidas de capital, sino también a verdaderos desastres.

A pesar de la naturaleza crítica de estos sistemas, los primeros sistemas de almacenamiento descentralizado seguro no aparecieron en el sector industrial, sino en el sector financiero. Las cuentas bancarias demostraron ser unRobonomics es uno de los líderes de estas redes seguras y descentralizadas, encargándose de la fase final del transportador de Web3 DevOps: la implementación.

En términos generales, una implementación es poner un sistema en funcionamiento. Un sinónimo más familiar para este término es instalación (instalar) - un evento después del cual el sistema producido y entregado (una instancia de un cierto tipo de equipo, un archivo ejecutable de software) comienza a funcionar dentro de un sistema de nivel superior. ¿Qué tiene de bueno la cadena de bloques en este caso? En primer lugar, al lanzar cualquier versión del programa al mundo exterior, siempre es importante para nosotros entender qué se lanzó exactamente. Durante el desarrollo, las versiones pueden cambiar muy a menudo y esto es normal, por lo que no es aconsejable poner toda la información sobre ellas en la cadena de bloques. Sin embargo, el evento de lanzamiento o puesta en marcha requiere una fijación, para que al recibir comentarios podamos entender claramente con qué versión exacta de códigos fuente o dibujos necesitamos comparar estos comentarios. La cadena de bloques puede servir como un repositorio confiable de información sobre todas las actualizaciones de software de los dispositivos conectados a ella.

Además, el proceso de instalación debe ser coherente, ya que las discrepancias pueden provocar colisiones de configuración. Estas colisiones pueden surgir de versiones de módulos de software incompatibles, despliegue de diferentes sistemas dentro del mismo espacio y otros problemas relacionados. Por ejemplo, la colisión de automóviles mencionada anteriormente en una intersección no regulada es un ejemplo de tal colisión. En el contexto de la implementación de software, las colisiones pueden manifestarse como violaciones de API, capacidades de hardware insuficientes o escritura en ubicaciones de memoria prohibidas o inseguras. Robonomics puede almacenar las configuraciones de los equipos conectados y, a nivel del algoritmo de consenso, prevenir tales estados.

Puedes utilizar una [llamada de lanzamiento](https://wiki.robonomics.network/docs/launch/) especial para implementar software en la paracadena de Robonomics, lo que te permite iniciar un nodo conectado a la cadena de bloques con parámetros adicionales. El parámetro puede ser un identificador único en la red de distribución de contenido de IPFS, desde el cual puedes obtener una imagen de software, un archivo binario, código fuente para la configuración del sistema operativo ¡o incluso un script de bash! Dado que cada transacción en la red está firmada con una clave criptográfica, en esencia, tal llamada en la paracadena es equivalente a una firma de lanzamiento público.

Para escenarios más complejos, puedes usar un [gemelo digital](https://wiki.robonomics.network/docs/digital-twins/), que permite establecer una tabla de correspondencia entre datos arbitrarios de 256 bits de longitud y una cuenta en la red de Robonomics. De esta manera, puedes llevar un registro de los cambios de versión de configuración para las cuentas de dispositivos en la red de Robonomics. En los sistemas tradicionales de configuración e implementación, los hosts suelen especificarse como nodos, que son computadoras con un nombre DNS o una dirección IP. En el caso de Web3, los hosts se identifican gracias a sus claves criptográficas públicas, a las cuales se adjuntan cuentas. Para cambiar la configuración, puedes agregar un nuevo identificador de contenido, a partir del cual el dispositivo recibirá una nueva versión del software y se actualizará.

## Poniéndolo todo junto

![pila de desarrollo web3 devops](/blog/images/web3-devops-stack/devop-stack-full-art.png)

Entonces, intentemos ver esto desde una perspectiva general. Las personas conforman el núcleo de nuestro gran sistema ciberfísico. Las personas son caóticas, impredecibles... ¡y eso es bueno! Generan nuevos significados, ideas, productos. Actualizan su voluntad de cambiar el mundo. Ahora, en el siglo XXI, no es necesario cambiar el mundo con tus propias manos. Hay tareas frente a la humanidad para las cuales las manos humanas no son la herramienta más adecuada. En su lugar, hay máquinas, que ahora sirven como conductores de nuestra voluntad. Las máquinas, por el contrario, son estrictamente deterministas y predecibles. Y a las personas les encanta esto, sí. Les encanta cuando el tren llega a la estación a tiempo, y la calidad de los productos que consumen es siempre excelente de manera predecible. Para esto, las personas utilizan redes. ¡Muchas redes! Generan ideas en la red de Radicle, las máquinas las recopilan y las prueban en módulos ejecutables en la red de Fluence, y luego las implementan en robots en la red de Robonomics. Los robots, a su vez, transforman el entorno, y sus sensores, también a través de Robonomics, proporcionan retroalimentación a las personas para tomar una decisión: el ciclo se cierra. Este es un ciclo de mejoras continuas, donde todos tienen su lugar. No hay contradicción entre la máquina y el humano, ambos en armonía crean un nuevo orden de la humanidad: la humanidad interplanetaria.