---
title: Stack DevOps Web3 per la Robotica
date: 2024-06-12
published: true
locale: 'it'
tags: ['DevOps', 'Web3']
cover_image: /blog/images/web3-devops-stack/web3-devops-stack-Cover.png
description: "Il movimento DevOps ha rivoluzionato il mondo dell'IT e ha ridefinito la nostra comprensione dell'efficace miglioramento continuo dei sistemi. Il campo della robotica sta appena iniziando a esplorare questo approccio. In questo articolo, immaginiamo il potenziale futuro del DevOps per la robotica utilizzando le tecnologie Web3. Evidenziamo anche alcuni progetti che potrebbero gettare le basi per questo futuro."
abstract: "Il movimento DevOps ha rivoluzionato il mondo dell'IT e ha ridefinito la nostra comprensione dell'efficace miglioramento continuo dei sistemi. Il campo della robotica sta appena iniziando a esplorare questo approccio. In questo articolo, immaginiamo il potenziale futuro del DevOps per la robotica utilizzando le tecnologie Web3. Evidenziamo anche alcuni progetti che potrebbero gettare le basi per questo futuro."
---

## Origini dello Sviluppo e delle Operazioni

I robot, come dispositivi che si muovono e percepiscono il mondo esterno, sono un caso specifico di computer. Come spesso dicono gli ingegneri, un aereo è un computer volante, sottolineando l'importanza del dispositivo di calcolo a bordo per mantenere la funzionalità di questo sistema cibernetico-fisico. Pertanto, possiamo osservare come il mondo dei sistemi informativi si sia sviluppato nel 21° secolo e identificare certe tendenze che saranno intrinseche alla robotica nel futuro molto prossimo.

Il software e le pratiche utilizzate per il suo sviluppo hanno cambiato significativamente gli approcci al lavoro sia nell'ingegneria che in qualsiasi altra attività. Innanzitutto, i cambiamenti hanno interessato l'approccio cosiddetto a cascata, quando ogni progetto veniva visto come una serie di lunghi stadi alternati: Requisiti - Sviluppo - Verifica - Convalida - Operazione. Nel tempo, è emerso che la divisione in fasi è comoda per i manager, ma non corrisponde esattamente a come avviene nella realtà e complica l'adattamento rapido dei prodotti alle condizioni di un mondo esterno in costante cambiamento. Le metodologie agili, che implicano un lavoro sincronizzato sul progetto con piccoli intervalli di pianificazione, sono venute a sostituire il modello a cascata di attività (e gestione). Invece di grandi fasi con milestone, c'erano piccole sprint con incrementi - cambiamenti piccoli ma frequenti nei sistemi sviluppati con un rilascio rapido. Tale ritmo di lavoro è irraggiungibile se il rilascio è accompagnato da complesse procedure amministrative con controlli manuali. Così è nato il movimento Sviluppo e Operazioni per implementare pratiche di trasferimento del valore dai sviluppatori ai consumatori senza perdite e una nuova professione di DevOps.Ingegnere operativo, automatizzazione del processo di avvio rapido del sistema.

![origini del DevOps](/blog/images/web3-devops-stack/devops-evolution.png)

Queste pratiche includono test automatizzati, integrazione continua, distribuzione, implementazione e monitoraggio del software. I test automatizzati verificano la presenza di bug, mentre l'integrazione continua integra frequentemente i cambiamenti del codice per rilevare tempestivamente eventuali problemi. La distribuzione e l'implementazione coinvolgono il fornire il software agli utenti e installarlo nel loro ambiente.

Inizialmente, queste pratiche hanno preso slancio nell'ambito dei grandi servizi web, che servono milioni di utenti in tutto il mondo. In un contesto del genere, queste pratiche sono cruciali per mantenere le alte prestazioni e l'affidabilità attese da tali servizi. Tuttavia, col passare del tempo e con la maggiore accessibilità degli strumenti di automazione (in parte grazie ai contributi open source), il DevOps ha iniziato ad essere utilizzato in attività di ingegneria più tradizionali. Di conseguenza, queste pratiche hanno superato il loro dominio iniziale e sono ora impiegate in vari settori per migliorare l'efficienza, l'affidabilità e la qualità dei prodotti software.

## Caratteristiche Chiave dei Robot nel Contesto del DevOps

I robot, a differenza dei server fissi e dei data center, si muovono nello spazio e percepiscono l'ambiente esterno. Sempre più di questi dispositivi stanno emergendo. Vediamo la loro potenza computazionale crescere nel tempo - molte soluzioni tecniche sarebbero semplicemente impossibili senza un potente processore integrato.

Con l'aumento del calcolo ai margini, che si riferisce al calcolo sui dispositivi mobili stessi, l'uso del DevOps sta diventando sempre più popolare. Questo approccio consente una rapida distribuzione delle nuove funzionalità sviluppate ai consumatori. I robot possono essere continuamente connessi alla rete e aggiornare prontamente il loro software utilizzando Docker e altri strumenti provati nella pratica.

Tuttavia, le capacità aggiuntive creano rischi aggiuntivi - conferendo ai computer la capacità di interagire intensamente con l'ambiente esterno e con Internet contemporaneamente, creiamo le premesse per i danni potenziali che questi dispositivi possono infliggere se cadono sotto il controllo di malintenzionati. I dispositivi intelligenti, che gradualmente riempiono le nostre case, potrebbero improvvisamente impazzire! La questione della sicurezza qui è di primaria importanza in un mondo in costante cambiamento, poiché tutti questi dispositivi sono in prossimità dei nostri corpi. Gli errori possono costare troppo.

Cosa rende la robotica speciale e la distingue dagli altri computer? Queste caratteristiche speciali includono:

1. Una varietà di piattaforme hardware (rispetto a un numero relativamente limitato di tipi di architettura di processori centrali)
2. Lavorare in ambienti imprevedibili, che implica la presenza di situazioni di emergenza - ad esempio, l'indisponibilità dei canali di comunicazione
3. Risorse limitate dei dispositivi di calcolo a bordo - processore debole, quantità relativamente piccola di memoria e bassa larghezza di banda di rete4. Requisiti di sicurezza aumentati
5. Un gran numero di dispositivi che richiedono aggiornamenti e nuove funzionalità

Considerando queste restrizioni, cercheremo di formulare una base concettuale per DevOps per robot basata su tecnologie Web3, almeno per la scrittura di codice, la costruzione e il rilascio. Cercheremo di presentare i progetti Web3 più interessanti in grado di garantire il funzionamento di un convoglio DevOps decentralizzato e mostrare come Robonomics possa diventarne parte integrante nella fase finale del ciclo di vita - durante l'implementazione dei programmi nel mondo esterno.

## Web3 e Blockchain

Quando parliamo di Web3, intendiamo principalmente la tecnologia Blockchain. Questi sono concetti strettamente correlati, ma non esattamente identici. Spesso sotto questo concetto si intende un intero insieme di tecnologie - crittografia a curva ellittica, reti P2P, algoritmo di consenso. I primi due punti non sono qualcosa di unico e sono ampiamente utilizzati nell'industria IT, mentre l'ultimo conferisce davvero alla blockchain una caratteristica speciale, rendendo questa soluzione uno strumento così potente. Ma abbiamo bisogno del consenso per tutte le situazioni della vita (e parti del convoglio DevOps)? Cerchiamo di capirlo.

Il consenso ha significati diversi in contesti diversi, ma la sua essenza è sempre invariata: sistemi, attori o agenti autonomi che compongono una rete decentralizzata giungono a un accordo su quale protocollo utilizzare nel lavoro e sullo stato dei dati comuni. Se le parti non giungono a un accordo, ciò porta al cosiddetto Fork. Storicamente, un fork implicava una divisione della blockchain, che portava alla divisione dei nodi di rete in due parti: alcuni nodi rimanevano "fedeli" alla vecchia versione del protocollo, mentre il resto passava alla nuova versione. Questo evento ha sempre avuto un contesto negativo: la comunità si riduceva invece di consolidarsi, rendendo il progetto in qualche modo più debole. Allo stesso tempo, come nell'evoluzione biologica, così come nella sua versione tecnologica osservata da noi ora sotto forma di economia, la ramificazione avviene costantemente e, inoltre, porta all'emergere di nuove forme di vita. Guarda l'albero della vita. Ogni ramo su di esso è un Fork che è avvenuto in tempi antichi: una mutazione ha dato origine a una nuova specie diventata incompatibile con i suoi simili. Senza questo meccanismo, la vita nella sua comprensione moderna sarebbe impossibile. È la capacità degli organismi di mutare che consente loro di adattarsi ai cambiamenti delle condizioni ambientali.

Così, giungiamo alla conclusione che il consenso è sia positivo, perché consente il coordinamento di molti attorie scalabilità, ma allo stesso tempo è negativo, perché ostacola l'emergere del nuovo, poiché coloro che si discostano dal consenso sono sempre considerati emarginati e il sistema in qualche modo li "spinge" via.

A differenza dell'evoluzione biologica, noi esseri umani portiamo avanti la tecno-evoluzione, e dipende da noi come avviene questa evoluzione. La fonte delle mutazioni nella tecnologia sono gli ingegneri, che applicano il metodo scientifico e il pensiero creativo per produrre nuove versioni della tecnologia più promettenti e valide. Traguardiamo più frequenti mutazioni, traiamo beneficio dalla decentralizzazione nel campo della generazione di nuove soluzioni efficaci sia per la tecnologia che per le organizzazioni. Al contrario, una situazione in cui un punto di vista "vince" e si raggiunge un consenso totale e incondizionato, è piena di rischi di collasso in determinate circostanze. Ecco perché la natura non ha seguito la strada della creazione di superorganismi delle dimensioni di un pianeta, ma ha seguito la strada della decentralizzazione - quando tutti gli esseri viventi sono dispersi tra nicchie ecologiche ed ecosistemi, rendendo la vita nel complesso stabile e addirittura stabilizzando il pianeta Terra secondo il [modello Daisyworld](https://it.wikipedia.org/wiki/Daisyworld) (in breve, grazie alla biosfera e alla sua diversità, il pianeta diventa più stabile).

Quindi, perché questa digressione? Principalmente, voglio sottolineare che non tutti i dati richiedono un consenso obbligatorio, rendendo la blockchain inappropriata per ogni scenario. Il consenso diventa necessario quando azioni non coordinate potrebbero comportare conseguenze irreversibili. Ad esempio, è cruciale agli incroci stradali. Se non c'è accordo sulle regole del traffico su quando andare e quando fermarsi, si può immaginare il potenziale caos!

Tornando all'argomento principale dell'articolo, si può presumere che il consenso sia appropriato dove i rischi sono elevati e, al contrario, nei casi in cui i rischi sono minimi, è più opportuno scegliere un sistema completamente decentralizzato senza consenso. Lo sviluppo del codice stesso è un'attività relativamente sicura, purché rimanga nello stato di sorgente o persino nei file eseguibili sul server di compilazione. Tuttavia, quando si tratta di implementare questi file nell'infrastruttura fisica del mondo reale, è molto importante essere coerenti. Ecco perché per i primi due punti del nostro stack DevOps (sviluppo e compilazione) abbiamo scelto progetti simili senza consenso.

## Prima Fase - Sviluppo - Radicle

![](/blog/images/web3-devops-stack/1st-phase-development.png)

Quindi, nello sviluppo del codice, è necessaria completa libertà e decentralizzazione per stimolaregenerazione delle migliori soluzioni direttamente dagli autori. Per fortuna, nell'industria dello sviluppo del codice, lo standard de-facto è diventato un sistema di controllo versione decentralizzato per design. Sto parlando, ovviamente, di git. git a priori non implica la presenza di un unico "fonte di verità" - ogni utente, prima di utilizzare il codice, deve clonare il repository sul proprio computer e lavorare con la propria copia locale. Inoltre, il metodo di archiviazione dei dati in git non è altro che una catena di blocchi (fatti fissi di modifiche del codice - commit), che garantiscono l'immutabilità della storia. In altre parole, git stesso è una sorta di blockchain, il consenso tra cui viene raggiunto manualmente dagli autori stessi attraverso il branching e le richieste di merge.

Tuttavia, nonostante la natura decentralizzata di git, le piattaforme web2 hanno preso il loro posto. Ora, lo sviluppo del codice è quasi interamente centralizzato attorno a un numero relativamente piccolo di piattaforme come Github, Bitbucket, Gitlab. E ciò è avvenuto proprio a causa dell'introduzione di strumenti aggiuntivi: DevOps (pipeline CI/CD, funzioni integrate per rilevare vulnerabilità nelle dipendenze del codice sorgente e molto altro) e Social Networking (sistemi di ricompensa per gli sviluppatori, tracciamento problemi, gestione progetti). Questi strumenti non fanno parte del protocollo git originale e complicano la migrazione dei progetti da una piattaforma all'altra.

Il progetto [Radicle](https://radicle.xyz/) è stato fondato appositamente con l'obiettivo di liberare gli sviluppatori di codice dalla dipendenza da grandi piattaforme, che consideriamo come il primo componente del nostro stack Web3-DevOps. Il progetto ha una [lunga storia](https://docs.radworks.org/community/our-story) e una serie di significative trasformazioni nel suo percorso verso il momento attuale. Inizialmente, Radicle è stato costruito sopra il sistema di archiviazione e hashing dei dati del repository di codice in IPFS, che stava guadagnando popolarità all'epoca, ma a un certo punto gli sviluppatori si resero conto che i modi di archiviazione e hashing dei dati del repository in IPFS erano incompatibili con i modi di archiviazione in git, portando alla duplicazione delle informazioni e al consumo eccessivo di traffico anche in caso di piccoli aggiornamenti. Gradualmente, si è presa la decisione di passare a una soluzione più minimalista - scambiare direttamente le patch di git, utilizzando il protocollo nativo [pack protocol](https://git-scm.com/docs/pack-protocol/en), per rendere questo il principale modo di trasmissione dei dati nella rete "codekeeper". Questa decisione ha segnato l'inizio di un importante refactoring e riscrittura del progetto da Go a Rust. La nuova versione del protocollo, chiamata Heartwoode draws inspiration from projects such as Secure Scuttlebutt (SSB) and Bitcoin's [Lightning Network](https://en.wikipedia.org/wiki/Lightning_Network).

Successivamente, nel 2021, l'Organizzazione Autonoma Decentralizzata (o semplicemente DAO) Radworks è stata fondata sulla blockchain di Ethereum, il token di governance RAD è stato emesso e i fondi necessari sono stati raccolti per lo sviluppo ulteriore del progetto. Apparentemente, il team del progetto non nega l'importanza dei componenti sociali ed economici nello sviluppo del codice, ma allo stesso tempo non cerca di integrare tutti gli strumenti di supporto nella loro implementazione. Una di queste iniziative è il loro progetto e contratto intelligente omonimo [Drips](https://www.drips.network/), che mira alla distribuzione automatica delle donazioni tra gli sviluppatori open source sotto lo slogan "Finanzia le tue dipendenze". All'interno di questo contratto intelligente, ogni progetto di sviluppo può impostare la ridistribuzione automatica delle donazioni ricevute per il proprio insieme di dipendenze (pacchetti, librerie).

Proprio di recente, nel marzo 2024, è stata rilasciata la versione 1.0.0 dell'implementazione del protocollo Heartwood, il che significa che può già essere presa in considerazione per scenari di produzione di pipeline di sviluppo decentralizzato.

## Seconda Fase - Costruzione, Test, Integrazione Continua - Fluence

![web3 build software](/blog/images/web3-devops-stack/2nd-phase-build.png)

Il passo successivo nel nostro pipeline semplificato di DevOps è la fase di costruzione, che include più di una semplice compilazione del codice. Coinvolge una serie di processi con intensità di risorse computazionali variabili. Tuttavia, questi calcoli non portano sempre a cambiamenti tangibili. In altre parole, non ogni modifica del codice o avvio della costruzione porta a un rilascio. Spesso, le pipeline di Integrazione Continua (CI) vengono eseguite su un programma. Gli artefatti che producono sono tipicamente di breve durata e vengono eliminati se non inclusi in un rilascio. Pertanto, non consideriamo questa fase nel ciclo di vita dello sviluppo come richiedente consenso, simile a numerosi progetti di cloud computing che utilizzano blockchain per la verifica dei risultati.

Gli sviluppatori di [Fluence](https://fluence.dev/) hanno una posizione simile. Si tratta di un progetto molto vicino a Robonomics, che utilizza anche intensivamente libP2P come strato di trasporto e ipfs come strato di archiviazione nei suoi casi d'uso, concentrandosi sull'orchestrazione dei peer e sui calcoli su di essi senza la necessità di piattaforme centralizzate. Approfondiamo la conoscenza su di loro.

Fluence è composto da due componenti chiave - Aqua e Marine. Il primo è un linguaggio specifico del dominio (DSL) e viene utilizzato per gestire la sequenza delle attività.su dispositivi informatici, cioè per orchestrare i peer. Da un lato, padroneggiare un'altra lingua può scoraggiare molti utenti, dall'altro è un passo onesto che ti prepara immediatamente per il futuro inevitabile. Il fatto è che la maggior parte delle piattaforme CI di solito offrono file di configurazione in alcuni formati comuni come YAML o JSON per gestire e configurare i flussi di lavoro. Inizialmente, questo è davvero conveniente e consente a qualsiasi utente senza competenze di programmazione di iniziare a lavorare, ma col tempo, man mano che le esigenze e, di conseguenza, il numero di configurazioni aumentano, la mancanza di strumenti così familiari per i programmatori porta alla crescita del codice boilerplate e all'incapacità di gestire la complessità. I tentativi di rendere YAML un linguaggio di configurazione utilizzando modelli non risolvono il problema, il che contribuisce all'emergere di linguaggi di descrizione della configurazione Ad-hoc come HCL (HashiCorp Configuration Language). Aqua offre una soluzione immediata sotto forma di linguaggio di programmazione dell'applicazione per il flusso di calcoli, che ha una solida base teorica sotto forma di Pi-calculus, in cui il codice Aqua viene compilato per l'esecuzione successiva sui peer. Questo rende la soglia di accesso alla tecnologia un po' più alta, ma dovrebbe idealmente garantire un lavoro più stabile e gestibile in futuro. Attualmente Aqua è un linguaggio piuttosto di basso livello, ma nel tempo potrebbero comparire librerie che implementano le migliori pratiche per progettare flussi di calcolo utilizzando comode astrazioni matematiche, il che accelererà lo sviluppo di calcoli distribuiti.

Aqua stabilisce l'ordine dei calcoli, ma i calcoli stessi sono preparati e eseguiti utilizzando Marine - un componente anch'esso sviluppato da Fluence. Marine è un SDK (Software Developers Kit) - un insieme di strumenti per assemblare moduli Webassembly mutualmente compatibili, nonché un Runtime - un ambiente generico per la loro esecuzione. I moduli sono componenti software relativamente indipendenti, ognuno dei quali conserva il proprio stato, ma può interagire tra loro tramite l'importazione/esportazione di funzioni. Un insieme di moduli interagenti forma un servizio, che implementa comportamenti complessi e agisce come attore nella rete peer di Fluence.

Insieme, Aqua e Marine forniscono pienamente ciò che può essere definito il pensiero di un sistema cibernetico-fisico - cioè, tutta la varietà di calcoli che aiutano a prendere decisioni su quali azioni intraprendere nel mondo esterno per aumentare le probabilità di successo nella corsa evolutiva.

Lo sviluppo della robotica basato su modelli richiede calcoli intensivi in termini di risorse. Una parte significativa dei test del software sviluppato per i robot viene effettuata in simulatori, e gli algoritmi basati sull'apprendimento per rinforzo avviano tali ambienti virtuali centinaia di migliaiadi volte prima di ottenere il comportamento desiderato dell'agente. Vari motori fisici e di rendering, così come i motori di gioco basati su di essi, possono fungere da ambienti virtuali. Di recente, il design pattern Entity Component System è diventato ampiamente diffuso in questi ambienti. A proposito, la versione moderna del noto simulatore robotico Gazebo/ex-Ignition di Open Robotics (che sviluppa anche ROS) utilizza anche [ECS](https://gazebosim.org/docs/harmonic/architecture) per aumentare le prestazioni e la flessibilità. Infatti, secondo gli sviluppatori di Fluence, il loro modello di esecuzione è ben adatto per l'implementazione di architetture distribuite costruite su questo principio.

Naturalmente, affinché il software compilato e testato porti valore, deve essere implementato su piattaforme hardware. Teoricamente, è anche possibile implementare il software utilizzando Fluence. Infatti, gli stessi sviluppatori affermano che la loro piattaforma consente anche l'implementazione su peer, e questo è effettivamente il caso. Tuttavia, riteniamo che sia necessario e importante il consenso nell'ambito dell'interazione con l'ambiente esterno e l'attrezzatura fisica.

## Terza Fase - Implementazione - Robonomics

![arte dell'implementazione robotica](/blog/images/web3-devops-stack/3rd-phase-deploy.png)

Una caratteristica importante del software è il fatto che non cambia il mondo esterno da solo, ma funge da modello della realtà circostante e aiuta a formulare ragionamenti su di essa - per costruire ipotesi, proporre un piano d'azione, avviare processi nel mondo esterno utilizzando attrezzature o persone. Ad esempio, un sistema di tracciamento delle problematiche non è di per sé un sistema che cambia il mondo esterno, può essere definito come un gemello digitale del team di sviluppo, che a sua volta porta cambiamenti alla vita. Grazie al sistema di tracciamento delle problematiche, il team può coordinare le azioni tra loro, aiutarsi reciprocamente. In altre parole, il sistema di tracciamento delle problematiche consente di mantenere un consenso all'interno del team di sviluppo - chi fa quali compiti e quando - ma il cambiamento stesso è realizzato dalle persone.

Nel discutere sistemi che cambiano il mondo, ci riferiamo a entità fisiche che operano nel mondo reale come dispositivi intelligenti, robot e fabbriche autonome. Fondamentalmente, Robonomics funge da ponte tra i sistemi informativi e le persone con il mondo esterno tramite sistemi robotici. L'importanza della sicurezza non può essere sottovalutata, poiché trascurarla potrebbe portare non solo a perdite di capitale, ma anche a veri disastri.

Nonostante la natura critica di questi sistemi, i primi sistemi di archiviazione decentralizzati sicuri sono apparsi non nel settore industriale, ma nel settore finanziario. I conti bancari si sono rivelati essereun obiettivo più allettante per i criminali informatici rispetto agli elettrodomestici, la maggior parte dei quali non aveva connettività di rete. La tecnologia utilizzata per proteggere i sistemi informativi bancari è evoluta significativamente, da SWIFT a Ethereum, ed è ora gradualmente implementata in altri settori economici.

Robonomics è all'avanguardia di queste reti sicure e decentralizzate, prendendo in carico la fase finale del convoglio Web3 DevOps - il rilascio.

In termini generali, un rilascio è mettere un sistema in funzione. Un sinonimo più familiare per questo termine è installazione (install) - un evento dopo il quale il sistema prodotto e consegnato (un'istanza di un certo tipo di attrezzatura, un file eseguibile di software) inizia la sua funzionalità all'interno di un sistema di livello superiore. Cosa c'è di buono nel blockchain in questo caso? Prima di tutto, quando rilasciamo qualsiasi versione del programma al mondo esterno, è sempre importante per noi capire cosa è stato esattamente rilasciato. Durante lo sviluppo, le versioni possono cambiare molto spesso ed è normale, quindi non è consigliabile inserire tutte le informazioni su di esse nel blockchain. Tuttavia, l'evento di rilascio o lancio richiede una fissazione, in modo che quando riceviamo feedback possiamo capire chiaramente con quale versione esatta di codici sorgente o disegni dobbiamo confrontare questo feedback. Il blockchain può fungere da deposito affidabile di informazioni su tutti gli aggiornamenti software dei dispositivi ad esso collegati.

Inoltre, il processo di installazione deve essere coerente, poiché le discrepanze possono portare a collisioni di configurazione. Queste collisioni possono derivare da versioni di moduli software non corrispondenti, dal rilascio di sistemi diversi nello stesso spazio e da altri problemi correlati. Ad esempio, la collisione automobilistica precedentemente menzionata in un incrocio non regolamentato è un esempio di tale collisione. Nel contesto del rilascio software, le collisioni possono manifestarsi come violazioni dell'API, capacità hardware insufficienti o scrittura in posizioni di memoria proibite o non sicure. Robonomics può memorizzare le configurazioni delle attrezzature collegate e, a livello dell'algoritmo di consenso, prevenire tali stati.

Puoi utilizzare una chiamata speciale [lancio](https://wiki.robonomics.network/docs/launch/) per distribuire software nella parachain di Robonomics, che ti consente di avviare un nodo collegato al blockchain con parametri aggiuntivi. Il parametro può essere un identificatore unico nella rete di distribuzione dei contenuti IPFS, da cui è possibile ottenere un'immagine software, un file binario, il codice sorgente per la configurazione del sistema operativo o addirittura uno script bash! Poiché ogni transazione nella rete è firmata con una chiave crittografica, in sostanza una tale chiamata nella parachain è equivalente a una firma di rilascio pubblica.

Per scenari più complessi, puoi utilizzare un [gemello digitale](https://wiki.robonomics.network/docs/digital-twins/), che consente di impostare una tabella di corrispondenza tra dati arbitrari lunghi 256 bit e un account nella rete Robonomics. In questo modo, è possibile mantenere un registro delle modifiche di versione della configurazione per gli account dei dispositivi nella rete Robonomics. Nei sistemi tradizionali di configurazione e distribuzione, gli host sono di solito specificati come nodi - si tratta di computer con un nome DNS o un indirizzo IP. Nel caso di Web3, gli host sono identificati grazie alle loro chiavi crittografiche pubbliche, a cui sono collegati gli account. Per modificare la configurazione, è possibile aggiungere un nuovo identificatore di contenuto, da cui il dispositivo riceverà una nuova versione del software e si aggiornerà.

## Mettendo tutto insieme

![web3 devops stack](/blog/images/web3-devops-stack/devop-stack-full-art.png)

Quindi, cerchiamo di guardare il tutto da un punto di vista panoramico. Le persone costituiscono il nucleo del nostro grande sistema cibernetico-fisico. Le persone sono caotiche, imprevedibili... e questo è positivo! Generano nuovi significati, idee, prodotti. Attualizzano la loro volontà di cambiare il mondo. Ora, nel 21° secolo, non è più necessario cambiare il mondo con le proprie mani. Ci sono compiti di fronte all'umanità per i quali le mani umane non sono lo strumento più adatto. Al contrario, ci sono macchine, che ora fungono da conduttori della nostra volontà. Le macchine, al contrario, sono rigorosamente deterministiche e prevedibili. E alle persone piace questo, sì. Amano quando il treno arriva in stazione in orario, e la qualità dei prodotti che consumano è sempre eccellente in modo prevedibile. Per questo, le persone utilizzano reti. Un sacco di reti! Generano idee sulla rete Radicle, le macchine le raccolgono e le testano in moduli eseguibili sulla rete Fluence, e poi le distribuiscono sui robot sulla rete Robonomics. I robot, a loro volta, trasformano l'ambiente, e i loro sensori, anche attraverso Robonomics, forniscono un feedback alle persone per prendere una decisione - il ciclo si chiude. Si tratta di un ciclo di miglioramenti continui, in cui ognuno ha il proprio posto. Non c'è contraddizione tra la macchina e l'essere umano - entrambi in armonia creano un nuovo ordine dell'umanità - umanità interplanetaria.