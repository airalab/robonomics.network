---
title: Pile de développement Web3 DevOps en robotique
date: 2024-06-12
published: true
locale: 'fr'
tags: ['DevOps', 'Web3']
cover_image: /blog/images/web3-devops-stack/web3-devops-stack-Cover.png
description: "Le mouvement DevOps a révolutionné le monde de l'informatique et a remodelé notre compréhension de l'amélioration continue et efficace des systèmes. Le domaine de la robotique commence tout juste à explorer cette approche. Dans cet article, nous envisageons le futur potentiel du DevOps pour la robotique en utilisant les technologies Web3. Nous mettons également en lumière quelques projets qui pourraient poser les bases de ce futur."
abstract: "Le mouvement DevOps a révolutionné le monde de l'informatique et a remodelé notre compréhension de l'amélioration continue et efficace des systèmes. Le domaine de la robotique commence tout juste à explorer cette approche. Dans cet article, nous envisageons le futur potentiel du DevOps pour la robotique en utilisant les technologies Web3. Nous mettons également en lumière quelques projets qui pourraient poser les bases de ce futur."
---

## Origines du développement et des opérations

Les robots, en tant que dispositifs mobiles et sensoriels explorant le monde extérieur, sont un cas spécifique d'ordinateurs. Comme le disent souvent les ingénieurs, un avion est un ordinateur volant, soulignant l'importance du dispositif informatique embarqué pour maintenir la viabilité de ce système cyber-physique. Par conséquent, nous pouvons examiner comment le monde des systèmes d'information s'est développé au 21e siècle et identifier certaines tendances qui seront inhérentes à la robotique dans un avenir très proche.

Les logiciels et les pratiques utilisées pour leur développement ont considérablement modifié les approches de travail tant dans l'ingénierie que dans toute autre activité. Tout d'abord, les changements ont affecté l'approche dite en cascade, lorsque tout projet était considéré comme une série d'étapes longues et alternées : Exigences - Développement - Vérification - Validation - Exploitation. Avec le temps, il est apparu que la division en étapes est pratique pour les gestionnaires, mais ne correspond pas tout à fait à ce qui se passe dans la réalité et complique l'adaptation rapide des produits dans des conditions d'un monde extérieur en constante évolution. Les méthodologies agiles, impliquant un travail synchrone sur le projet avec de petits intervalles de planification, sont venues remplacer le modèle en cascade d'activité (et de gestion). Au lieu de grandes étapes avec des jalons, il y avait de petits sprints avec des incréments - des changements petits mais fréquents dans les systèmes développés avec une sortie rapide. Un tel rythme de travail est inatteignable si la sortie est accompagnée de procédures administratives complexes avec des vérifications manuelles. Ainsi, le mouvement Développement & Opérations a émergé pour mettre en œuvre des pratiques de transfert de valeur des développeurs aux consommateurs sans pertes et une nouvelle profession de DevOps.Ingénieur Ops, automatisant le processus de mise en service rapide du système.

![origines de DevOps](/blog/images/web3-devops-stack/devops-evolution.png)

Ces pratiques incluent les tests automatisés, l'intégration continue, la livraison, le déploiement et la surveillance logicielle. Les tests automatisés vérifient les bugs, tandis que l'intégration continue intègre fréquemment les changements de code pour détecter les problèmes tôt. La livraison et le déploiement impliquent de fournir le logiciel aux utilisateurs et de l'installer dans leur environnement.

Initialement, ces pratiques ont gagné du terrain dans le domaine des grands services web, qui servent des millions d'utilisateurs à travers le monde. Dans un tel contexte, ces pratiques sont cruciales pour maintenir les performances élevées et la fiabilité attendues de tels services. Cependant, avec le temps et l'accessibilité croissante des outils d'automatisation (en partie grâce aux contributions open source), DevOps a commencé à être utilisé dans des activités d'ingénierie plus traditionnelles. Ainsi, ces pratiques ont dépassé leur domaine initial et sont désormais utilisées dans divers secteurs pour améliorer l'efficacité, la fiabilité et la qualité des produits logiciels.

## Caractéristiques clés des robots dans le contexte de DevOps

Les robots, contrairement aux serveurs stationnaires et aux centres de données, se déplacent dans l'espace et perçoivent l'environnement externe. De plus en plus de ces appareils émergent. Nous voyons leur puissance de calcul augmenter avec le temps - de nombreuses solutions techniques seraient tout simplement impossibles sans un processeur embarqué puissant.

Avec l'essor de l'informatique périphérique, qui fait référence à l'informatique sur les appareils mobiles eux-mêmes, l'utilisation de DevOps devient de plus en plus populaire. Cette approche permet une livraison rapide des nouvelles fonctionnalités développées aux consommateurs. Les robots peuvent être continuellement connectés au réseau et mettre à jour rapidement leur logiciel en utilisant Docker et d'autres outils éprouvés en pratique.

Cependant, des capacités supplémentaires créent des risques supplémentaires - en donnant aux ordinateurs la capacité d'interagir intensivement avec l'environnement externe et Internet simultanément, nous créons les conditions préalables aux dommages potentiels que ces appareils peuvent causer s'ils tombent sous le contrôle de malfaiteurs. Les appareils intelligents, qui envahissent progressivement nos foyers, peuvent soudainement devenir fous ! La question de la sécurité est ici d'une importance capitale dans un monde en constante évolution, car tous ces appareils sont à proximité de nos corps. Les erreurs peuvent coûter trop cher.

Qu'est-ce qui rend la robotique spéciale et la distingue des autres ordinateurs ? Ces caractéristiques spéciales incluent :

1. Une variété de plateformes matérielles (par rapport à un nombre relativement restreint de types d'architecture de processeur central)
2. Travailler dans des environnements imprévisibles, ce qui implique la survenue de situations d'urgence - par exemple, l'indisponibilité des canaux de communication
3. Des ressources limitées des appareils informatiques embarqués - processeur faible, quantité de mémoire relativement petite et faible bande passante réseau4. Exigences de sécurité accrues
5. Un grand nombre d'appareils nécessitant des mises à jour et de nouvelles fonctionnalités

En tenant compte de ces restrictions, nous allons essayer de formuler une base conceptuelle pour DevOps pour les robots basée sur les technologies Web3, au moins pour l'écriture de code, la construction et le déploiement. Nous allons essayer de présenter les projets Web3 les plus intéressants capables d'assurer le fonctionnement d'un convoyeur DevOps décentralisé et montrer comment Robonomics peut devenir une partie intégrante de celui-ci dans la phase finale du cycle de vie - lors de la mise en œuvre de programmes dans le monde extérieur.

## Web3 et Blockchain

Lorsque nous parlons de Web3, nous entendons principalement la technologie Blockchain. Ce sont bien sûr des concepts étroitement liés, mais pas exactement identiques. Souvent, sous ce concept, tout un ensemble de technologies est implicite - la cryptographie à courbes elliptiques, les réseaux P2P, l'algorithme de consensus. Les deux premiers points ne sont pas quelque chose d'unique et sont largement utilisés dans l'industrie informatique, tandis que le dernier confère vraiment à la blockchain une caractéristique spéciale, faisant de cette solution un outil si puissant. Mais avons-nous besoin de consensus pour toutes les situations de la vie (et les parties du convoyeur DevOps)? Essayons de comprendre.

Le consensus a des significations différentes dans différents contextes, mais son essence est toujours la même - les systèmes, les acteurs ou les agents autonomes qui composent un réseau décentralisé parviennent à un accord sur le protocole à utiliser dans le travail et l'état des données communes. Si les parties ne parviennent pas à un accord, cela conduit à ce qu'on appelle une fourchette. Historiquement, une fourchette impliquait une division de la blockchain, ce qui conduisait à la division des nœuds du réseau en deux parties - certains nœuds restaient "fidèles" à l'ancienne version du protocole, tandis que le reste passait à la nouvelle version. Cet événement avait toujours un contexte négatif - la communauté diminuait au lieu de se consolider, ce qui rendait le projet quelque peu plus faible. En même temps, comme dans l'évolution biologique, ainsi que dans sa version technologique que nous observons maintenant sous forme d'économie, des ramifications se produisent constamment et, de plus, elles conduisent à l'émergence de nouvelles formes de vie. Regardez l'arbre de vie. Chaque branche est une fourchette qui s'est produite dans les temps anciens - une mutation a donné naissance à une nouvelle espèce devenue incompatible avec ses semblables. Sans ce mécanisme, la vie dans sa compréhension moderne serait impossible. C'est la capacité des organismes à muter qui leur permet de s'adapter aux conditions environnementales changeantes.

Ainsi, nous en venons à la conclusion que le consensus est à la fois bon, car il permet la coordination de nombreux acteurset la scalabilité, mais en même temps, c'est mauvais, car cela entrave l'émergence du nouveau, car ceux qui s'écartent du consensus sont toujours considérés comme des parias et le système les "pousse" en quelque sorte à l'extérieur.

Contrairement à l'évolution biologique, nous, les humains, réalisons une techno-évolution, et c'est à nous de décider comment cette évolution se déroule. La source de mutations en technologie est les ingénieurs, appliquant la méthode scientifique et la pensée créative pour produire de nouvelles versions de technologie plus prometteuses et viables. Nous bénéficions de mutations plus fréquentes, nous bénéficions de la décentralisation dans le domaine de la génération de nouvelles solutions efficaces tant en matière de technologie que d'organisations. Au contraire - une situation où un point de vue "gagne" et où un consensus complet et inconditionnel est atteint, est risquée et peut entraîner un effondrement dans certaines circonstances. C'est pourquoi la nature n'a pas suivi la voie de la création de super-organismes de la taille d'une planète, mais a opté pour la décentralisation - lorsque tous les êtres vivants sont dispersés à travers des niches écologiques et des écosystèmes, ce qui rend la vie dans son ensemble stable et stabilise même la planète Terre selon le [modèle Daisyworld](https://fr.wikipedia.org/wiki/Daisyworld) (en bref, grâce à la biosphère et à sa diversité, la planète devient plus stable).

Alors, pourquoi cette digression? Principalement, je tiens à souligner que toutes les données ne nécessitent pas un consensus obligatoire, rendant la blockchain inappropriée pour chaque scénario. Le consensus devient nécessaire lorsque des actions non coordonnées pourraient entraîner des conséquences irréversibles. Par exemple, il est crucial aux intersections routières. S'il n'y a pas d'accord sur les règles de circulation concernant le moment de passer et le moment de s'arrêter, vous pouvez imaginer le chaos potentiel !

Revenant au sujet principal de l'article, on peut supposer que le consensus est approprié là où les risques sont élevés et, inversement, dans les cas où les risques sont faibles, il est plus approprié de choisir un système complètement décentralisé sans consensus. Le développement de code lui-même est une activité relativement sûre, tant qu'il reste à l'état de fichiers source ou même de fichiers exécutables sur le serveur de construction. Cependant, lorsqu'il s'agit de déployer ces fichiers dans l'infrastructure physique du monde réel, il est très important d'être cohérent. C'est pourquoi pour les deux premiers points de notre pile DevOps (développement et construction), nous avons choisi des projets partageant les mêmes idées sans consensus.

## Première phase - Développement - Radicle

![](/blog/images/web3-devops-stack/1st-phase-development.png)

Ainsi, dans le développement de code, une liberté totale et une décentralisation sont nécessaires pour stimulergénère les meilleures solutions directement des auteurs. Heureusement pour nous, dans l'industrie du développement de code, la norme de facto est devenue un système de contrôle de version décentralisé par conception. Je parle bien sûr de git. git a priori n'implique pas la présence d'une seule "source de vérité" - tout utilisateur, avant d'utiliser le code, doit cloner le dépôt sur son ordinateur et travailler avec sa copie locale. De plus, la méthode de stockage des données dans git n'est rien d'autre qu'une chaîne de blocs (faits fixes des changements de code - commits), qui garantissent l'immuabilité de l'historique. Autrement dit, git lui-même est une sorte de blockchain, dont le consensus est atteint manuellement par les auteurs eux-mêmes grâce aux branches et aux demandes de fusion.

Néanmoins, malgré la nature décentralisée de git, les plateformes web2 ont pris leur place. Aujourd'hui, le développement de code est presque entièrement centralisé autour d'un nombre relativement restreint de plateformes comme Github, Bitbucket, Gitlab. Et cela s'est produit précisément en raison de l'introduction d'outils supplémentaires : DevOps (pipelines CI/CD, fonctions intégrées pour détecter les vulnérabilités dans les dépendances du code source et bien plus encore) et les réseaux sociaux (systèmes de récompense pour les développeurs, suivi des problèmes, gestion de projets). Ces outils ne font pas partie du protocole git original et compliquent la migration des projets d'une plateforme à une autre.

Le projet [Radicle](https://radicle.xyz/) a été fondé spécifiquement dans le but de libérer les développeurs de code de la nécessité de dépendre de grandes plateformes, que nous considérons comme le premier composant de notre pile Web3-DevOps. Le projet a une [histoire assez longue](https://docs.radworks.org/community/our-story) et un certain nombre de transformations significatives sur son chemin vers son moment actuel. Initialement, Radicle était construit sur la File System Inter Planetary (IPFS) qui gagnait alors en popularité, mais à un moment donné, les développeurs ont réalisé que les façons de stocker et de hacher les données du dépôt de code dans IPFS étaient incompatibles avec les façons de stocker dans git, entraînant une duplication des informations et une consommation excessive de trafic même en cas de petites mises à jour. Progressivement, une décision a été prise de passer à une solution plus minimaliste - échanger directement des correctifs git, en utilisant le protocole natif [pack protocol](https://git-scm.com/docs/pack-protocol/en), pour en faire le principal moyen de transmission des données dans le réseau "codekeeper". Cette décision a marqué le début d'une refonte majeure et d'une réécriture du projet de Go à Rust. La nouvelle version du protocole, appelée Heartwood,puise son inspiration de projets tels que Secure Scuttlebutt (SSB) et le [réseau Lightning](https://fr.wikipedia.org/wiki/Réseau_Lightning) de Bitcoin.

Plus tard, en 2021, l'Organisation Autonome Décentralisée (ou simplement DAO) Radworks a été fondée sur la blockchain Ethereum, le jeton de gouvernance RAD a été émis, et les fonds nécessaires ont été levés pour le développement ultérieur du projet. Apparemment, l'équipe du projet ne nie pas l'importance des composantes sociales et économiques dans le développement de code, mais en même temps ne cherche pas à intégrer tous les outils de soutien dans leur implémentation. Une telle initiative est leur projet et leur contrat intelligent éponyme [Drips](https://www.drips.network/), qui vise à la distribution automatique des dons parmi les développeurs de logiciels open source sous le slogan "Financez vos dépendances". Dans ce contrat intelligent, chaque projet de développement peut mettre en place une redistribution automatique des dons reçus pour son ensemble de dépendances (packages, bibliothèques).

Récemment, en mars 2024, la version 1.0.0 de l'implémentation du protocole Heartwood a été publiée, ce qui signifie qu'elle peut déjà être envisagée pour des scénarios de production de pipelines de développement décentralisés.

## Deuxième phase - Construction, Test, Intégration Continue - Fluence

![construction de logiciels web3](/blog/images/web3-devops-stack/2nd-phase-build.png)

L'étape suivante de notre pipeline DevOps simplifié est l'étape de construction, qui ne se limite pas à la compilation du code. Elle implique toute une série de processus avec des intensités de ressources computationnelles variables. Cependant, ces calculs ne conduisent pas toujours à des changements tangibles. En d'autres termes, chaque modification de code ou lancement de construction ne se traduit pas nécessairement par une publication. Souvent, les pipelines d'Intégration Continue (CI) s'exécutent selon un calendrier. Les artefacts qu'ils produisent sont généralement de courte durée et sont supprimés s'ils ne sont pas inclus dans une publication. Par conséquent, nous ne considérons pas cette étape du cycle de vie du développement comme nécessitant un consensus, similaire à de nombreux projets de cloud computing qui utilisent la blockchain pour la vérification des résultats.

Les développeurs de [Fluence](https://fluence.dev/) adoptent une position similaire. Il s'agit d'un projet très proche de Robonomics, qui utilise également intensivement libP2P comme couche de transport et ipfs comme couche de stockage dans ses cas d'utilisation, tout en se concentrant sur l'orchestration des pairs et les calculs sur eux sans avoir besoin de plates-formes centralisées. Examinons-les de plus près.

Fluence se compose de deux composants clés - Aqua et Marine. Le premier est un langage spécifique à un domaine (DSL) et est utilisé pour gérer la séquence des tâchessur les appareils informatiques, c'est-à-dire orchestrer des pairs. D'une part, maîtriser une autre langue peut dissuader de nombreux utilisateurs, d'autre part, c'est une démarche honnête qui vous prépare immédiatement à l'avenir inévitable. Le fait est que la plupart des plateformes CI offrent généralement des fichiers de configuration dans des formats courants tels que YAML ou JSON pour gérer et configurer des pipelines. Au début, c'est vraiment pratique et permet à tout utilisateur sans compétences en programmation de commencer à travailler, mais avec le temps, à mesure que les besoins et, en conséquence, le nombre de configurations augmentent, le manque d'outils si familiers pour les programmeurs conduit à la croissance du code redondant et à l'incapacité de gérer la complexité. Les tentatives de faire de YAML un langage de configuration en utilisant des modèles ne résolvent pas non plus le problème, ce qui contribue à l'émergence de langages de description de configuration Ad-hoc comme HCL (HashiCorp Configuration Language). Aqua offre une solution immédiate sous la forme d'un langage de programmation d'application pour le flux de calculs, qui repose sur une base théorique fiable sous la forme de Pi-calcul, dans lequel le code Aqua est compilé pour une exécution ultérieure sur des pairs. Cela rend le seuil d'entrée dans la technologie un peu plus élevé, mais devrait idéalement fournir un travail plus stable et plus maintenable à l'avenir. Actuellement, Aqua est un langage assez bas niveau, mais avec le temps, des bibliothèques pourraient apparaître qui mettent en œuvre les meilleures pratiques pour concevoir des flux de calculs en utilisant des abstractions mathématiques pratiques, ce qui accélérera le développement de calculs distribués.

Aqua définit l'ordre des calculs, mais les calculs eux-mêmes sont préparés et exécutés à l'aide de Marine - un composant également développé par Fluence. Marine est un SDK (Software Developers Kit) - un ensemble d'outils pour assembler des modules Webassembly mutuellement compatibles, ainsi qu'un Runtime - un environnement polyvalent pour leur exécution. Les modules sont des composants logiciels relativement indépendants, chacun stockant son propre état, mais pouvant interagir les uns avec les autres via des fonctions d'import/export. Un ensemble de modules interagissant forme un service, qui met en œuvre un comportement complexe et agit comme un acteur dans le réseau de pairs de Fluence.

Ensemble, Aqua et Marine fournissent pleinement ce qu'on pourrait appeler la réflexion d'un système cyber-physique - c'est-à-dire toute la variété de calculs qui aident à prendre des décisions sur les actions à entreprendre dans le monde extérieur pour augmenter les chances de succès dans la course à l'évolution.

Le développement de la robotique basé sur des modèles nécessite des calculs intensifs en ressources. Une partie significative des tests du logiciel développé pour les robots est réalisée dans des simulateurs, et les algorithmes basés sur l'apprentissage par renforcement lancent de tels environnements virtuels des centaines de milliersde fois avant d'obtenir le comportement d'agent souhaité. Divers moteurs physiques et de rendu, ainsi que des moteurs de jeu basés sur eux, peuvent servir d'environnements virtuels. Récemment, le modèle de conception Entity Component System est devenu répandu dans ces environnements. En passant, la version moderne du simulateur robotique bien connu dans les cercles restreints Gazebo/ex-Ignition d'Open Robotics (ils développent également ROS) utilise également [ECS](https://gazebosim.org/docs/harmonic/architecture) pour augmenter les performances et la flexibilité. En fait, selon les développeurs de Fluence, leur modèle d'exécution est bien adapté à la mise en œuvre d'architectures distribuées basées sur ce principe.

Bien sûr, pour que le logiciel compilé et testé apporte de la valeur, il doit être déployé sur des plateformes matérielles. Hypothétiquement, il est également possible de déployer un logiciel à l'aide de Fluence. En fait, les développeurs eux-mêmes affirment que leur pile permet également le déploiement sur des pairs, et c'est effectivement le cas. Cependant, nous pensons qu'un consensus est nécessaire et important dans le domaine de l'interaction avec l'environnement externe et l'équipement physique.

## Troisième phase - Déploiement - Robonomics

![art du déploiement robotique](/blog/images/web3-devops-stack/3rd-phase-deploy.png)

Une caractéristique importante du logiciel est le fait qu'il ne modifie pas le monde extérieur par lui-même, mais sert de modèle de la réalité environnante et aide à raisonner à ce sujet - pour formuler des hypothèses, proposer un plan d'action, lancer des processus dans le monde extérieur en utilisant de l'équipement ou des personnes. Par exemple, un gestionnaire de problèmes n'est pas en soi un système qui modifie le monde extérieur, on peut le considérer comme un jumeau numérique de l'équipe de développement, qui à son tour apporte des changements dans la vie. Grâce au gestionnaire de problèmes, l'équipe peut coordonner ses actions les unes avec les autres, s'entraider. En d'autres termes, le gestionnaire de problèmes permet de maintenir un consensus au sein de l'équipe de développement - qui fait quelles tâches et quand - mais le changement lui-même est effectué par des personnes.

Lorsque nous discutons de systèmes changeant le monde, nous faisons référence à des entités physiques opérant dans le monde réel telles que des appareils intelligents, des robots et des usines autonomes. Fondamentalement, Robonomics sert de pont entre les systèmes d'information et les personnes vers le monde extérieur via des systèmes robotiques. L'importance de la sécurité ne peut être surestimée, car la négliger pourrait entraîner non seulement des pertes financières, mais aussi de véritables catastrophes.

Malgré la nature critique de ces systèmes, les premiers systèmes de stockage décentralisés sécurisés sont apparus non pas dans le secteur industriel, mais dans le secteur financier. Les comptes bancaires se sont avérés êtreUne cible plus attrayante pour les criminels informatiques que les appareils ménagers, dont la plupart ne disposaient pas de connectivité réseau. La technologie utilisée pour sécuriser les systèmes d'information bancaire a évolué de manière significative, passant de SWIFT à Ethereum, et est maintenant progressivement mise en œuvre dans d'autres secteurs économiques.

Robonomics est à l'avant-garde de ces réseaux sécurisés et décentralisés, prenant en charge la phase finale du convoyeur Web3 DevOps - le déploiement.

En termes généraux, un déploiement consiste à mettre un système en service. Un synonyme plus familier de ce terme est l'installation - un événement après lequel le système produit et livré (une instance d'un certain type d'équipement, un fichier exécutable de logiciel) commence à fonctionner à l'intérieur d'un système de niveau supérieur. Qu'est-ce qui est bon avec la blockchain dans ce cas ? Tout d'abord, lors de la publication de n'importe quelle version du programme dans le monde extérieur, il est toujours important pour nous de comprendre ce qui a été exactement publié. Pendant le développement, les versions peuvent changer très souvent et c'est normal, il n'est donc pas conseillé de mettre toutes les informations à leur sujet dans la blockchain. Cependant, l'événement de publication ou de lancement nécessite une fixation, de sorte que lors de la réception des retours, nous puissions comprendre clairement avec quelle version exacte des codes sources ou des dessins nous devons comparer ce retour. La blockchain peut servir de référentiel fiable d'informations sur toutes les mises à jour logicielles des appareils qui y sont connectés.

De plus, le processus d'installation doit être cohérent, car des divergences peuvent entraîner des collisions de configuration. Ces collisions peuvent survenir en raison de versions de modules logiciels incompatibles, du déploiement de différents systèmes dans le même espace et d'autres problèmes connexes. Par exemple, la collision de voitures mentionnée précédemment à une intersection non réglementée est un exemple de ce type de collision. Dans le contexte du déploiement de logiciels, les collisions peuvent se manifester sous la forme de violations d'API, de capacités matérielles insuffisantes ou d'écriture dans des emplacements mémoire interdits ou non sécurisés. Robonomics peut stocker les configurations des équipements connectés et, au niveau de l'algorithme de consensus, prévenir de tels états.

Vous pouvez utiliser un appel de [lancement](https://wiki.robonomics.network/docs/launch/) spécial pour déployer des logiciels dans la parachain Robonomics, ce qui vous permet de démarrer un nœud connecté à la blockchain avec des paramètres supplémentaires. Le paramètre peut être un identifiant unique dans le réseau de distribution de contenu IPFS, à partir duquel vous pouvez obtenir une image logicielle, un fichier binaire, du code source pour la configuration du système d'exploitation, ou même un script bash ! Comme chaque transaction dans le réseau est signée avec une clé cryptographique, en essence, un tel appel dans la parachain est équivalent à une signature de publication publique.

Pour des scénarios plus complexes, vous pouvez utiliser un [jumeau numérique](https://wiki.robonomics.network/docs/digital-twins/), qui permet de définir une table de correspondance entre des données arbitraires de 256 bits de long et un compte dans le réseau Robonomics. Ainsi, vous pouvez conserver un journal des modifications de version de configuration pour les comptes de périphériques dans le réseau Robonomics. Dans les systèmes de configuration et de déploiement traditionnels, les hôtes sont généralement spécifiés en tant que nœuds - ce sont des ordinateurs avec un nom DNS ou une adresse IP. Dans le cas de Web3, les hôtes sont identifiés grâce à leurs clés cryptographiques publiques, auxquelles des comptes sont attachés. Pour changer la configuration, vous pouvez ajouter un nouvel identifiant de contenu, à partir duquel le périphérique recevra une nouvelle version du logiciel et se mettra à jour.

## Mettons tout cela ensemble

![pile web3 devops](/blog/images/web3-devops-stack/devop-stack-full-art.png)

Alors, essayons de voir cela d'un point de vue global. Les personnes constituent le cœur de notre grand système cyber-physique. Les personnes sont chaotiques, imprévisibles... et c'est bien ! Elles génèrent de nouvelles significations, idées, produits. Elles actualisent leur volonté de changer le monde. Maintenant, au 21e siècle, il n'est pas nécessaire de changer le monde de ses propres mains. Il y a des tâches devant l'humanité pour lesquelles les mains humaines ne sont pas l'outil le plus adapté. À la place, il y a des machines, qui servent maintenant de vecteur à notre volonté. Les machines, au contraire, sont strictement déterministes et prévisibles. Et les gens aiment ça, oui. Ils aiment quand le train arrive à l'heure à la gare, et que la qualité des produits qu'ils consomment est toujours excellente de manière prévisible. Pour cela, les gens utilisent des réseaux. Beaucoup de réseaux ! Ils génèrent des idées sur le réseau Radicle, les machines les rassemblent et les testent en modules exécutables sur le réseau Fluence, puis les déploient sur des robots sur le réseau Robonomics. Les robots, à leur tour, transforment l'environnement, et leurs capteurs, également via Robonomics, fournissent des retours aux personnes pour prendre une décision - le cycle est bouclé. Il s'agit d'un cycle d'améliorations continues, où chacun a sa place. Il n'y a pas de contradiction entre la machine et l'humain - tous les deux en harmonie créent un nouvel ordre de l'humanité - l'humanité interplanétaire.